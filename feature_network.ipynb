{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from input_preparation import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "from feature_preprocess import feature_vector\n",
    "from input_preparation import *\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2048, input_shape=(2014,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2048)              4126720   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18)                18450     \n",
      "=================================================================\n",
      "Total params: 6,243,346\n",
      "Trainable params: 6,243,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 32488\n",
    "nb_validation_samples = 5723\n",
    "batch_size = 32\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 32488\n",
      "number of test examples = 5723\n",
      "X_train shape: (32488, 2014)\n",
      "Y_train shape: (32488, 18)\n",
      "X_test shape: (5723, 2014)\n",
      "Y_test shape: (5723, 18)\n"
     ]
    }
   ],
   "source": [
    "from resnets_utils import*\n",
    "\n",
    "# initiate the train and validation generators with data augumentation\n",
    "X_train, Y_train_orig, X_test, Y_test_orig = load_dataset()\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 18)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 18)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "# save the model according to the conditions\n",
    "checkpoint = ModelCheckpoint(\"models/feature_network.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32488 samples, validate on 5723 samples\n",
      "Epoch 1/1000\n",
      "32488/32488 [==============================] - 21s 638us/step - loss: 2.8762 - acc: 0.0728 - val_loss: 2.8493 - val_acc: 0.0956\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.09558, saving model to models/feature_network.h5\n",
      "Epoch 2/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 2.8481 - acc: 0.0841 - val_loss: 2.8335 - val_acc: 0.0940\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.8391 - acc: 0.0867 - val_loss: 2.8268 - val_acc: 0.0949\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.8346 - acc: 0.0891 - val_loss: 2.8231 - val_acc: 0.0954\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.8319 - acc: 0.0899 - val_loss: 2.8204 - val_acc: 0.0992\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.09558 to 0.09925, saving model to models/feature_network.h5\n",
      "Epoch 6/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.8303 - acc: 0.0922 - val_loss: 2.8182 - val_acc: 0.0977\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.8266 - acc: 0.0963 - val_loss: 2.8162 - val_acc: 0.1008\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.09925 to 0.10082, saving model to models/feature_network.h5\n",
      "Epoch 8/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.8253 - acc: 0.0990 - val_loss: 2.8144 - val_acc: 0.1066\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.10082 to 0.10659, saving model to models/feature_network.h5\n",
      "Epoch 9/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.8228 - acc: 0.0987 - val_loss: 2.8126 - val_acc: 0.1085\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.10659 to 0.10851, saving model to models/feature_network.h5\n",
      "Epoch 10/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.8223 - acc: 0.0992 - val_loss: 2.8108 - val_acc: 0.1138\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.10851 to 0.11375, saving model to models/feature_network.h5\n",
      "Epoch 11/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 2.8194 - acc: 0.1023 - val_loss: 2.8090 - val_acc: 0.1206\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.11375 to 0.12057, saving model to models/feature_network.h5\n",
      "Epoch 12/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.8174 - acc: 0.1053 - val_loss: 2.8072 - val_acc: 0.1235\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.12057 to 0.12354, saving model to models/feature_network.h5\n",
      "Epoch 13/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.8159 - acc: 0.1047 - val_loss: 2.8053 - val_acc: 0.1248\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.12354 to 0.12476, saving model to models/feature_network.h5\n",
      "Epoch 14/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.8146 - acc: 0.1074 - val_loss: 2.8035 - val_acc: 0.1230\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.8109 - acc: 0.1072 - val_loss: 2.8014 - val_acc: 0.1277\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.12476 to 0.12773, saving model to models/feature_network.h5\n",
      "Epoch 16/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.8106 - acc: 0.1121 - val_loss: 2.7993 - val_acc: 0.1323\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.12773 to 0.13227, saving model to models/feature_network.h5\n",
      "Epoch 17/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 2.8079 - acc: 0.1127 - val_loss: 2.7972 - val_acc: 0.1358\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.13227 to 0.13577, saving model to models/feature_network.h5\n",
      "Epoch 18/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 2.8063 - acc: 0.1105 - val_loss: 2.7950 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 2.8043 - acc: 0.1148 - val_loss: 2.7928 - val_acc: 0.1358\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.8023 - acc: 0.1159 - val_loss: 2.7905 - val_acc: 0.1373\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.13577 to 0.13734, saving model to models/feature_network.h5\n",
      "Epoch 21/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.8002 - acc: 0.1201 - val_loss: 2.7881 - val_acc: 0.1375\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.13734 to 0.13752, saving model to models/feature_network.h5\n",
      "Epoch 22/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7975 - acc: 0.1197 - val_loss: 2.7857 - val_acc: 0.1387\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.13752 to 0.13874, saving model to models/feature_network.h5\n",
      "Epoch 23/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.7933 - acc: 0.1223 - val_loss: 2.7829 - val_acc: 0.1412\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.13874 to 0.14118, saving model to models/feature_network.h5\n",
      "Epoch 24/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7908 - acc: 0.1214 - val_loss: 2.7801 - val_acc: 0.1422\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.14118 to 0.14223, saving model to models/feature_network.h5\n",
      "Epoch 25/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.7898 - acc: 0.1269 - val_loss: 2.7774 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.14223 to 0.14293, saving model to models/feature_network.h5\n",
      "Epoch 26/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7899 - acc: 0.1261 - val_loss: 2.7746 - val_acc: 0.1449\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.14293 to 0.14485, saving model to models/feature_network.h5\n",
      "Epoch 27/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7858 - acc: 0.1256 - val_loss: 2.7715 - val_acc: 0.1480\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.14485 to 0.14800, saving model to models/feature_network.h5\n",
      "Epoch 28/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7827 - acc: 0.1316 - val_loss: 2.7684 - val_acc: 0.1510\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.14800 to 0.15097, saving model to models/feature_network.h5\n",
      "Epoch 29/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.7803 - acc: 0.1310 - val_loss: 2.7653 - val_acc: 0.1508\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.7771 - acc: 0.1305 - val_loss: 2.7621 - val_acc: 0.1515\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.15097 to 0.15149, saving model to models/feature_network.h5\n",
      "Epoch 31/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7737 - acc: 0.1320 - val_loss: 2.7587 - val_acc: 0.1511\n",
      "\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.7710 - acc: 0.1320 - val_loss: 2.7553 - val_acc: 0.1525\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.15149 to 0.15254, saving model to models/feature_network.h5\n",
      "Epoch 33/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.7683 - acc: 0.1314 - val_loss: 2.7516 - val_acc: 0.1536\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.15254 to 0.15359, saving model to models/feature_network.h5\n",
      "Epoch 34/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7644 - acc: 0.1346 - val_loss: 2.7478 - val_acc: 0.1552\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.15359 to 0.15516, saving model to models/feature_network.h5\n",
      "Epoch 35/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7624 - acc: 0.1400 - val_loss: 2.7441 - val_acc: 0.1559\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.15516 to 0.15586, saving model to models/feature_network.h5\n",
      "Epoch 36/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7579 - acc: 0.1409 - val_loss: 2.7400 - val_acc: 0.1573\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.15586 to 0.15726, saving model to models/feature_network.h5\n",
      "Epoch 37/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.7544 - acc: 0.1397 - val_loss: 2.7358 - val_acc: 0.1564\n",
      "\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.7505 - acc: 0.1436 - val_loss: 2.7315 - val_acc: 0.1576\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.15726 to 0.15761, saving model to models/feature_network.h5\n",
      "Epoch 39/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.7472 - acc: 0.1448 - val_loss: 2.7270 - val_acc: 0.1587\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.15761 to 0.15866, saving model to models/feature_network.h5\n",
      "Epoch 40/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.7438 - acc: 0.1450 - val_loss: 2.7224 - val_acc: 0.1588\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.15866 to 0.15883, saving model to models/feature_network.h5\n",
      "Epoch 41/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.7397 - acc: 0.1465 - val_loss: 2.7176 - val_acc: 0.1599\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.15883 to 0.15988, saving model to models/feature_network.h5\n",
      "Epoch 42/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.7363 - acc: 0.1488 - val_loss: 2.7126 - val_acc: 0.1623\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.15988 to 0.16233, saving model to models/feature_network.h5\n",
      "Epoch 43/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.7301 - acc: 0.1520 - val_loss: 2.7074 - val_acc: 0.1625\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.16233 to 0.16250, saving model to models/feature_network.h5\n",
      "Epoch 44/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.7276 - acc: 0.1496 - val_loss: 2.7022 - val_acc: 0.1637\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.16250 to 0.16373, saving model to models/feature_network.h5\n",
      "Epoch 45/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 2.7233 - acc: 0.1556 - val_loss: 2.6966 - val_acc: 0.1642\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.16373 to 0.16425, saving model to models/feature_network.h5\n",
      "Epoch 46/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.7166 - acc: 0.1554 - val_loss: 2.6907 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.16425 to 0.16809, saving model to models/feature_network.h5\n",
      "Epoch 47/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.7121 - acc: 0.1573 - val_loss: 2.6848 - val_acc: 0.1690\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.16809 to 0.16897, saving model to models/feature_network.h5\n",
      "Epoch 48/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.7072 - acc: 0.1585 - val_loss: 2.6785 - val_acc: 0.1704\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.16897 to 0.17037, saving model to models/feature_network.h5\n",
      "Epoch 49/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.7033 - acc: 0.1578 - val_loss: 2.6722 - val_acc: 0.1742\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.17037 to 0.17421, saving model to models/feature_network.h5\n",
      "Epoch 50/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6949 - acc: 0.1623 - val_loss: 2.6652 - val_acc: 0.1742\n",
      "\n",
      "Epoch 00050: val_acc did not improve\n",
      "Epoch 51/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.6872 - acc: 0.1663 - val_loss: 2.6582 - val_acc: 0.1768\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.17421 to 0.17683, saving model to models/feature_network.h5\n",
      "Epoch 52/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6843 - acc: 0.1637 - val_loss: 2.6511 - val_acc: 0.1775\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.17683 to 0.17753, saving model to models/feature_network.h5\n",
      "Epoch 53/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6788 - acc: 0.1646 - val_loss: 2.6435 - val_acc: 0.1808\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.17753 to 0.18085, saving model to models/feature_network.h5\n",
      "Epoch 54/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6708 - acc: 0.1678 - val_loss: 2.6361 - val_acc: 0.1808\n",
      "\n",
      "Epoch 00054: val_acc did not improve\n",
      "Epoch 55/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6626 - acc: 0.1698 - val_loss: 2.6283 - val_acc: 0.1817\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.18085 to 0.18172, saving model to models/feature_network.h5\n",
      "Epoch 56/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6570 - acc: 0.1713 - val_loss: 2.6200 - val_acc: 0.1842\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.18172 to 0.18417, saving model to models/feature_network.h5\n",
      "Epoch 57/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6494 - acc: 0.1747 - val_loss: 2.6116 - val_acc: 0.1878\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.18417 to 0.18784, saving model to models/feature_network.h5\n",
      "Epoch 58/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6406 - acc: 0.1765 - val_loss: 2.6028 - val_acc: 0.1896\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.18784 to 0.18959, saving model to models/feature_network.h5\n",
      "Epoch 59/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6362 - acc: 0.1746 - val_loss: 2.5945 - val_acc: 0.1891\n",
      "\n",
      "Epoch 00059: val_acc did not improve\n",
      "Epoch 60/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.6255 - acc: 0.1777 - val_loss: 2.5858 - val_acc: 0.1910\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.18959 to 0.19098, saving model to models/feature_network.h5\n",
      "Epoch 61/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6185 - acc: 0.1785 - val_loss: 2.5765 - val_acc: 0.1950\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.19098 to 0.19500, saving model to models/feature_network.h5\n",
      "Epoch 62/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.6134 - acc: 0.1832 - val_loss: 2.5679 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.19500 to 0.19588, saving model to models/feature_network.h5\n",
      "Epoch 63/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.6035 - acc: 0.1837 - val_loss: 2.5590 - val_acc: 0.1961\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.19588 to 0.19605, saving model to models/feature_network.h5\n",
      "Epoch 64/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.5947 - acc: 0.1867 - val_loss: 2.5496 - val_acc: 0.1987\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.19605 to 0.19867, saving model to models/feature_network.h5\n",
      "Epoch 65/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.5864 - acc: 0.1882 - val_loss: 2.5403 - val_acc: 0.2006\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.19867 to 0.20059, saving model to models/feature_network.h5\n",
      "Epoch 66/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.5769 - acc: 0.1912 - val_loss: 2.5311 - val_acc: 0.2022\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.20059 to 0.20217, saving model to models/feature_network.h5\n",
      "Epoch 67/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.5689 - acc: 0.1901 - val_loss: 2.5225 - val_acc: 0.2018\n",
      "\n",
      "Epoch 00067: val_acc did not improve\n",
      "Epoch 68/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 2.5603 - acc: 0.1894 - val_loss: 2.5133 - val_acc: 0.2065\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.20217 to 0.20654, saving model to models/feature_network.h5\n",
      "Epoch 69/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.5569 - acc: 0.1930 - val_loss: 2.5048 - val_acc: 0.2072\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.20654 to 0.20723, saving model to models/feature_network.h5\n",
      "Epoch 70/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.5488 - acc: 0.1906 - val_loss: 2.4965 - val_acc: 0.2085\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.20723 to 0.20846, saving model to models/feature_network.h5\n",
      "Epoch 71/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.5366 - acc: 0.1985 - val_loss: 2.4880 - val_acc: 0.2093\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.20846 to 0.20933, saving model to models/feature_network.h5\n",
      "Epoch 72/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.5299 - acc: 0.1977 - val_loss: 2.4792 - val_acc: 0.2125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: val_acc improved from 0.20933 to 0.21248, saving model to models/feature_network.h5\n",
      "Epoch 73/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.5227 - acc: 0.2000 - val_loss: 2.4708 - val_acc: 0.2121\n",
      "\n",
      "Epoch 00073: val_acc did not improve\n",
      "Epoch 74/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.5162 - acc: 0.2022 - val_loss: 2.4631 - val_acc: 0.2137\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.21248 to 0.21370, saving model to models/feature_network.h5\n",
      "Epoch 75/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.5099 - acc: 0.2024 - val_loss: 2.4560 - val_acc: 0.2200\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.21370 to 0.21999, saving model to models/feature_network.h5\n",
      "Epoch 76/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.5004 - acc: 0.2050 - val_loss: 2.4475 - val_acc: 0.2160\n",
      "\n",
      "Epoch 00076: val_acc did not improve\n",
      "Epoch 77/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.4903 - acc: 0.2045 - val_loss: 2.4403 - val_acc: 0.2181\n",
      "\n",
      "Epoch 00077: val_acc did not improve\n",
      "Epoch 78/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.4865 - acc: 0.2056 - val_loss: 2.4333 - val_acc: 0.2200\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.21999 to 0.21999, saving model to models/feature_network.h5\n",
      "Epoch 79/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.4795 - acc: 0.2077 - val_loss: 2.4257 - val_acc: 0.2244\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.21999 to 0.22436, saving model to models/feature_network.h5\n",
      "Epoch 80/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.4707 - acc: 0.2115 - val_loss: 2.4187 - val_acc: 0.2259\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.22436 to 0.22593, saving model to models/feature_network.h5\n",
      "Epoch 81/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.4646 - acc: 0.2124 - val_loss: 2.4125 - val_acc: 0.2265\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.22593 to 0.22645, saving model to models/feature_network.h5\n",
      "Epoch 82/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.4581 - acc: 0.2127 - val_loss: 2.4052 - val_acc: 0.2280\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.22645 to 0.22803, saving model to models/feature_network.h5\n",
      "Epoch 83/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.4524 - acc: 0.2117 - val_loss: 2.3996 - val_acc: 0.2265\n",
      "\n",
      "Epoch 00083: val_acc did not improve\n",
      "Epoch 84/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.4489 - acc: 0.2100 - val_loss: 2.3938 - val_acc: 0.2289\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.22803 to 0.22890, saving model to models/feature_network.h5\n",
      "Epoch 85/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.4425 - acc: 0.2170 - val_loss: 2.3870 - val_acc: 0.2293\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.22890 to 0.22925, saving model to models/feature_network.h5\n",
      "Epoch 86/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.4329 - acc: 0.2184 - val_loss: 2.3821 - val_acc: 0.2320\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.22925 to 0.23205, saving model to models/feature_network.h5\n",
      "Epoch 87/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.4292 - acc: 0.2192 - val_loss: 2.3754 - val_acc: 0.2303\n",
      "\n",
      "Epoch 00087: val_acc did not improve\n",
      "Epoch 88/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.4249 - acc: 0.2202 - val_loss: 2.3705 - val_acc: 0.2326\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.23205 to 0.23257, saving model to models/feature_network.h5\n",
      "Epoch 89/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.4183 - acc: 0.2193 - val_loss: 2.3652 - val_acc: 0.2327\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.23257 to 0.23275, saving model to models/feature_network.h5\n",
      "Epoch 90/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.4143 - acc: 0.2228 - val_loss: 2.3600 - val_acc: 0.2341\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.23275 to 0.23414, saving model to models/feature_network.h5\n",
      "Epoch 91/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.4074 - acc: 0.2232 - val_loss: 2.3542 - val_acc: 0.2383\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.23414 to 0.23834, saving model to models/feature_network.h5\n",
      "Epoch 92/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.4021 - acc: 0.2247 - val_loss: 2.3489 - val_acc: 0.2364\n",
      "\n",
      "Epoch 00092: val_acc did not improve\n",
      "Epoch 93/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.3954 - acc: 0.2251 - val_loss: 2.3436 - val_acc: 0.2396\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.23834 to 0.23956, saving model to models/feature_network.h5\n",
      "Epoch 94/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3910 - acc: 0.2274 - val_loss: 2.3395 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00094: val_acc did not improve\n",
      "Epoch 95/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.3862 - acc: 0.2298 - val_loss: 2.3347 - val_acc: 0.2399\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.23956 to 0.23991, saving model to models/feature_network.h5\n",
      "Epoch 96/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.3830 - acc: 0.2271 - val_loss: 2.3309 - val_acc: 0.2401\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.23991 to 0.24008, saving model to models/feature_network.h5\n",
      "Epoch 97/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3786 - acc: 0.2312 - val_loss: 2.3256 - val_acc: 0.2410\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.24008 to 0.24096, saving model to models/feature_network.h5\n",
      "Epoch 98/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.3727 - acc: 0.2318 - val_loss: 2.3211 - val_acc: 0.2427\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.24096 to 0.24270, saving model to models/feature_network.h5\n",
      "Epoch 99/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.3722 - acc: 0.2302 - val_loss: 2.3171 - val_acc: 0.2436\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.24270 to 0.24358, saving model to models/feature_network.h5\n",
      "Epoch 100/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3648 - acc: 0.2330 - val_loss: 2.3133 - val_acc: 0.2443\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.24358 to 0.24428, saving model to models/feature_network.h5\n",
      "Epoch 101/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3583 - acc: 0.2333 - val_loss: 2.3088 - val_acc: 0.2476\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.24428 to 0.24760, saving model to models/feature_network.h5\n",
      "Epoch 102/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3556 - acc: 0.2383 - val_loss: 2.3046 - val_acc: 0.2462\n",
      "\n",
      "Epoch 00102: val_acc did not improve\n",
      "Epoch 103/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3506 - acc: 0.2373 - val_loss: 2.3002 - val_acc: 0.2483\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.24760 to 0.24830, saving model to models/feature_network.h5\n",
      "Epoch 104/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.3503 - acc: 0.2378 - val_loss: 2.2967 - val_acc: 0.2513\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.24830 to 0.25127, saving model to models/feature_network.h5\n",
      "Epoch 105/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.3431 - acc: 0.2418 - val_loss: 2.2931 - val_acc: 0.2537\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.25127 to 0.25371, saving model to models/feature_network.h5\n",
      "Epoch 106/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3393 - acc: 0.2439 - val_loss: 2.2900 - val_acc: 0.2523\n",
      "\n",
      "Epoch 00106: val_acc did not improve\n",
      "Epoch 107/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3367 - acc: 0.2391 - val_loss: 2.2850 - val_acc: 0.2537\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.25371 to 0.25371, saving model to models/feature_network.h5\n",
      "Epoch 108/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.3329 - acc: 0.2400 - val_loss: 2.2824 - val_acc: 0.2565\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.25371 to 0.25651, saving model to models/feature_network.h5\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.3248 - acc: 0.2444 - val_loss: 2.2774 - val_acc: 0.2551\n",
      "\n",
      "Epoch 00109: val_acc did not improve\n",
      "Epoch 110/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3237 - acc: 0.2444 - val_loss: 2.2740 - val_acc: 0.2579\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.25651 to 0.25791, saving model to models/feature_network.h5\n",
      "Epoch 111/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3177 - acc: 0.2467 - val_loss: 2.2708 - val_acc: 0.2588\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.25791 to 0.25878, saving model to models/feature_network.h5\n",
      "Epoch 112/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3149 - acc: 0.2473 - val_loss: 2.2673 - val_acc: 0.2593\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.25878 to 0.25930, saving model to models/feature_network.h5\n",
      "Epoch 113/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3109 - acc: 0.2500 - val_loss: 2.2631 - val_acc: 0.2614\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.25930 to 0.26140, saving model to models/feature_network.h5\n",
      "Epoch 114/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3092 - acc: 0.2486 - val_loss: 2.2598 - val_acc: 0.2618\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.26140 to 0.26175, saving model to models/feature_network.h5\n",
      "Epoch 115/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3048 - acc: 0.2492 - val_loss: 2.2562 - val_acc: 0.2628\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.26175 to 0.26280, saving model to models/feature_network.h5\n",
      "Epoch 116/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.3038 - acc: 0.2502 - val_loss: 2.2550 - val_acc: 0.2628\n",
      "\n",
      "Epoch 00116: val_acc did not improve\n",
      "Epoch 117/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2985 - acc: 0.2508 - val_loss: 2.2509 - val_acc: 0.2663\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.26280 to 0.26629, saving model to models/feature_network.h5\n",
      "Epoch 118/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2951 - acc: 0.2490 - val_loss: 2.2470 - val_acc: 0.2656\n",
      "\n",
      "Epoch 00118: val_acc did not improve\n",
      "Epoch 119/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2912 - acc: 0.2533 - val_loss: 2.2441 - val_acc: 0.2675\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.26629 to 0.26752, saving model to models/feature_network.h5\n",
      "Epoch 120/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2879 - acc: 0.2558 - val_loss: 2.2406 - val_acc: 0.2691\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.26752 to 0.26909, saving model to models/feature_network.h5\n",
      "Epoch 121/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2841 - acc: 0.2538 - val_loss: 2.2375 - val_acc: 0.2707\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.26909 to 0.27066, saving model to models/feature_network.h5\n",
      "Epoch 122/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2834 - acc: 0.2564 - val_loss: 2.2346 - val_acc: 0.2714\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.27066 to 0.27136, saving model to models/feature_network.h5\n",
      "Epoch 123/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2787 - acc: 0.2581 - val_loss: 2.2313 - val_acc: 0.2729\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.27136 to 0.27293, saving model to models/feature_network.h5\n",
      "Epoch 124/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2766 - acc: 0.2578 - val_loss: 2.2285 - val_acc: 0.2752\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.27293 to 0.27521, saving model to models/feature_network.h5\n",
      "Epoch 125/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2731 - acc: 0.2569 - val_loss: 2.2250 - val_acc: 0.2756\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.27521 to 0.27555, saving model to models/feature_network.h5\n",
      "Epoch 126/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2691 - acc: 0.2622 - val_loss: 2.2222 - val_acc: 0.2773\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.27555 to 0.27730, saving model to models/feature_network.h5\n",
      "Epoch 127/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2647 - acc: 0.2611 - val_loss: 2.2195 - val_acc: 0.2773\n",
      "\n",
      "Epoch 00127: val_acc did not improve\n",
      "Epoch 128/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2629 - acc: 0.2631 - val_loss: 2.2177 - val_acc: 0.2790\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.27730 to 0.27905, saving model to models/feature_network.h5\n",
      "Epoch 129/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2581 - acc: 0.2659 - val_loss: 2.2127 - val_acc: 0.2766\n",
      "\n",
      "Epoch 00129: val_acc did not improve\n",
      "Epoch 130/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2582 - acc: 0.2612 - val_loss: 2.2105 - val_acc: 0.2785\n",
      "\n",
      "Epoch 00130: val_acc did not improve\n",
      "Epoch 131/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2531 - acc: 0.2673 - val_loss: 2.2075 - val_acc: 0.2794\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.27905 to 0.27940, saving model to models/feature_network.h5\n",
      "Epoch 132/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2472 - acc: 0.2665 - val_loss: 2.2038 - val_acc: 0.2824\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.27940 to 0.28237, saving model to models/feature_network.h5\n",
      "Epoch 133/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2456 - acc: 0.2646 - val_loss: 2.2012 - val_acc: 0.2832\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.28237 to 0.28324, saving model to models/feature_network.h5\n",
      "Epoch 134/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2457 - acc: 0.2676 - val_loss: 2.1983 - val_acc: 0.2829\n",
      "\n",
      "Epoch 00134: val_acc did not improve\n",
      "Epoch 135/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2406 - acc: 0.2722 - val_loss: 2.1954 - val_acc: 0.2829\n",
      "\n",
      "Epoch 00135: val_acc did not improve\n",
      "Epoch 136/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2371 - acc: 0.2702 - val_loss: 2.1921 - val_acc: 0.2860\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.28324 to 0.28604, saving model to models/feature_network.h5\n",
      "Epoch 137/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.2344 - acc: 0.2711 - val_loss: 2.1890 - val_acc: 0.2831\n",
      "\n",
      "Epoch 00137: val_acc did not improve\n",
      "Epoch 138/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2307 - acc: 0.2725 - val_loss: 2.1869 - val_acc: 0.2843\n",
      "\n",
      "Epoch 00138: val_acc did not improve\n",
      "Epoch 139/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2286 - acc: 0.2711 - val_loss: 2.1852 - val_acc: 0.2866\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.28604 to 0.28656, saving model to models/feature_network.h5\n",
      "Epoch 140/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2254 - acc: 0.2734 - val_loss: 2.1816 - val_acc: 0.2878\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.28656 to 0.28779, saving model to models/feature_network.h5\n",
      "Epoch 141/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2209 - acc: 0.2759 - val_loss: 2.1785 - val_acc: 0.2911\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.28779 to 0.29111, saving model to models/feature_network.h5\n",
      "Epoch 142/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.2190 - acc: 0.2740 - val_loss: 2.1755 - val_acc: 0.2906\n",
      "\n",
      "Epoch 00142: val_acc did not improve\n",
      "Epoch 143/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2147 - acc: 0.2795 - val_loss: 2.1727 - val_acc: 0.2899\n",
      "\n",
      "Epoch 00143: val_acc did not improve\n",
      "Epoch 144/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.2133 - acc: 0.2770 - val_loss: 2.1701 - val_acc: 0.2901\n",
      "\n",
      "Epoch 00144: val_acc did not improve\n",
      "Epoch 145/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2126 - acc: 0.2775 - val_loss: 2.1685 - val_acc: 0.2915\n",
      "\n",
      "Epoch 00145: val_acc improved from 0.29111 to 0.29146, saving model to models/feature_network.h5\n",
      "Epoch 146/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.2069 - acc: 0.2780 - val_loss: 2.1646 - val_acc: 0.2927\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.29146 to 0.29268, saving model to models/feature_network.h5\n",
      "Epoch 147/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.2074 - acc: 0.2766 - val_loss: 2.1635 - val_acc: 0.2932\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.29268 to 0.29320, saving model to models/feature_network.h5\n",
      "Epoch 148/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.2043 - acc: 0.2816 - val_loss: 2.1592 - val_acc: 0.2915\n",
      "\n",
      "Epoch 00148: val_acc did not improve\n",
      "Epoch 149/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1946 - acc: 0.2844 - val_loss: 2.1567 - val_acc: 0.2943\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.29320 to 0.29425, saving model to models/feature_network.h5\n",
      "Epoch 150/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1952 - acc: 0.2847 - val_loss: 2.1534 - val_acc: 0.2969\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.29425 to 0.29687, saving model to models/feature_network.h5\n",
      "Epoch 151/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.1908 - acc: 0.2834 - val_loss: 2.1518 - val_acc: 0.2953\n",
      "\n",
      "Epoch 00151: val_acc did not improve\n",
      "Epoch 152/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1906 - acc: 0.2843 - val_loss: 2.1490 - val_acc: 0.2998\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.29687 to 0.29984, saving model to models/feature_network.h5\n",
      "Epoch 153/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1859 - acc: 0.2852 - val_loss: 2.1458 - val_acc: 0.2995\n",
      "\n",
      "Epoch 00153: val_acc did not improve\n",
      "Epoch 154/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1857 - acc: 0.2859 - val_loss: 2.1437 - val_acc: 0.2990\n",
      "\n",
      "Epoch 00154: val_acc did not improve\n",
      "Epoch 155/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1835 - acc: 0.2876 - val_loss: 2.1408 - val_acc: 0.3004\n",
      "\n",
      "Epoch 00155: val_acc improved from 0.29984 to 0.30037, saving model to models/feature_network.h5\n",
      "Epoch 156/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1825 - acc: 0.2871 - val_loss: 2.1384 - val_acc: 0.3035\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.30037 to 0.30351, saving model to models/feature_network.h5\n",
      "Epoch 157/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1739 - acc: 0.2919 - val_loss: 2.1362 - val_acc: 0.2998\n",
      "\n",
      "Epoch 00157: val_acc did not improve\n",
      "Epoch 158/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1727 - acc: 0.2911 - val_loss: 2.1330 - val_acc: 0.3032\n",
      "\n",
      "Epoch 00158: val_acc did not improve\n",
      "Epoch 159/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1677 - acc: 0.2902 - val_loss: 2.1316 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.30351 to 0.30404, saving model to models/feature_network.h5\n",
      "Epoch 160/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1686 - acc: 0.2912 - val_loss: 2.1284 - val_acc: 0.3051\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.30404 to 0.30508, saving model to models/feature_network.h5\n",
      "Epoch 161/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1685 - acc: 0.2912 - val_loss: 2.1262 - val_acc: 0.3060\n",
      "\n",
      "Epoch 00161: val_acc improved from 0.30508 to 0.30596, saving model to models/feature_network.h5\n",
      "Epoch 162/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1620 - acc: 0.2922 - val_loss: 2.1230 - val_acc: 0.3074\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.30596 to 0.30736, saving model to models/feature_network.h5\n",
      "Epoch 163/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1625 - acc: 0.2926 - val_loss: 2.1200 - val_acc: 0.3070\n",
      "\n",
      "Epoch 00163: val_acc did not improve\n",
      "Epoch 164/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1604 - acc: 0.2936 - val_loss: 2.1183 - val_acc: 0.3105\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.30736 to 0.31050, saving model to models/feature_network.h5\n",
      "Epoch 165/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1562 - acc: 0.2976 - val_loss: 2.1174 - val_acc: 0.3074\n",
      "\n",
      "Epoch 00165: val_acc did not improve\n",
      "Epoch 166/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1530 - acc: 0.2931 - val_loss: 2.1130 - val_acc: 0.3115\n",
      "\n",
      "Epoch 00166: val_acc improved from 0.31050 to 0.31155, saving model to models/feature_network.h5\n",
      "Epoch 167/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1481 - acc: 0.2950 - val_loss: 2.1099 - val_acc: 0.3093\n",
      "\n",
      "Epoch 00167: val_acc did not improve\n",
      "Epoch 168/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1492 - acc: 0.2998 - val_loss: 2.1083 - val_acc: 0.3126\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.31155 to 0.31260, saving model to models/feature_network.h5\n",
      "Epoch 169/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1445 - acc: 0.2978 - val_loss: 2.1064 - val_acc: 0.3143\n",
      "\n",
      "Epoch 00169: val_acc improved from 0.31260 to 0.31435, saving model to models/feature_network.h5\n",
      "Epoch 170/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.1383 - acc: 0.3020 - val_loss: 2.1031 - val_acc: 0.3110\n",
      "\n",
      "Epoch 00170: val_acc did not improve\n",
      "Epoch 171/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1368 - acc: 0.3015 - val_loss: 2.1003 - val_acc: 0.3142\n",
      "\n",
      "Epoch 00171: val_acc did not improve\n",
      "Epoch 172/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1385 - acc: 0.3011 - val_loss: 2.0981 - val_acc: 0.3140\n",
      "\n",
      "Epoch 00172: val_acc did not improve\n",
      "Epoch 173/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1350 - acc: 0.3042 - val_loss: 2.0957 - val_acc: 0.3126\n",
      "\n",
      "Epoch 00173: val_acc did not improve\n",
      "Epoch 174/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1324 - acc: 0.3038 - val_loss: 2.0926 - val_acc: 0.3157\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.31435 to 0.31574, saving model to models/feature_network.h5\n",
      "Epoch 175/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.1237 - acc: 0.3059 - val_loss: 2.0914 - val_acc: 0.3157\n",
      "\n",
      "Epoch 00175: val_acc did not improve\n",
      "Epoch 176/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1285 - acc: 0.3036 - val_loss: 2.0875 - val_acc: 0.3177\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.31574 to 0.31767, saving model to models/feature_network.h5\n",
      "Epoch 177/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1240 - acc: 0.3083 - val_loss: 2.0861 - val_acc: 0.3192\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.31767 to 0.31924, saving model to models/feature_network.h5\n",
      "Epoch 178/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1220 - acc: 0.3062 - val_loss: 2.0831 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00178: val_acc did not improve\n",
      "Epoch 179/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1186 - acc: 0.3076 - val_loss: 2.0808 - val_acc: 0.3182\n",
      "\n",
      "Epoch 00179: val_acc did not improve\n",
      "Epoch 180/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1154 - acc: 0.3106 - val_loss: 2.0780 - val_acc: 0.3201\n",
      "\n",
      "Epoch 00180: val_acc improved from 0.31924 to 0.32011, saving model to models/feature_network.h5\n",
      "Epoch 181/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1147 - acc: 0.3066 - val_loss: 2.0764 - val_acc: 0.3222\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.32011 to 0.32221, saving model to models/feature_network.h5\n",
      "Epoch 182/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1114 - acc: 0.3110 - val_loss: 2.0759 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00182: val_acc improved from 0.32221 to 0.32238, saving model to models/feature_network.h5\n",
      "Epoch 183/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.1060 - acc: 0.3110 - val_loss: 2.0714 - val_acc: 0.3248\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.32238 to 0.32483, saving model to models/feature_network.h5\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1044 - acc: 0.3140 - val_loss: 2.0688 - val_acc: 0.3247\n",
      "\n",
      "Epoch 00184: val_acc did not improve\n",
      "Epoch 185/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.1025 - acc: 0.3125 - val_loss: 2.0699 - val_acc: 0.3240\n",
      "\n",
      "Epoch 00185: val_acc did not improve\n",
      "Epoch 186/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0987 - acc: 0.3168 - val_loss: 2.0643 - val_acc: 0.3259\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.32483 to 0.32588, saving model to models/feature_network.h5\n",
      "Epoch 187/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0934 - acc: 0.3139 - val_loss: 2.0625 - val_acc: 0.3271\n",
      "\n",
      "Epoch 00187: val_acc improved from 0.32588 to 0.32710, saving model to models/feature_network.h5\n",
      "Epoch 188/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.0926 - acc: 0.3157 - val_loss: 2.0599 - val_acc: 0.3268\n",
      "\n",
      "Epoch 00188: val_acc did not improve\n",
      "Epoch 189/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0920 - acc: 0.3145 - val_loss: 2.0580 - val_acc: 0.3275\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.32710 to 0.32745, saving model to models/feature_network.h5\n",
      "Epoch 190/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0884 - acc: 0.3187 - val_loss: 2.0554 - val_acc: 0.3285\n",
      "\n",
      "Epoch 00190: val_acc improved from 0.32745 to 0.32850, saving model to models/feature_network.h5\n",
      "Epoch 191/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0831 - acc: 0.3176 - val_loss: 2.0543 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00191: val_acc improved from 0.32850 to 0.33042, saving model to models/feature_network.h5\n",
      "Epoch 192/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0862 - acc: 0.3180 - val_loss: 2.0500 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00192: val_acc improved from 0.33042 to 0.33199, saving model to models/feature_network.h5\n",
      "Epoch 193/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0842 - acc: 0.3201 - val_loss: 2.0488 - val_acc: 0.3337\n",
      "\n",
      "Epoch 00193: val_acc improved from 0.33199 to 0.33374, saving model to models/feature_network.h5\n",
      "Epoch 194/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0827 - acc: 0.3215 - val_loss: 2.0464 - val_acc: 0.3306\n",
      "\n",
      "Epoch 00194: val_acc did not improve\n",
      "Epoch 195/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0792 - acc: 0.3212 - val_loss: 2.0469 - val_acc: 0.3287\n",
      "\n",
      "Epoch 00195: val_acc did not improve\n",
      "Epoch 196/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.0747 - acc: 0.3224 - val_loss: 2.0424 - val_acc: 0.3353\n",
      "\n",
      "Epoch 00196: val_acc improved from 0.33374 to 0.33531, saving model to models/feature_network.h5\n",
      "Epoch 197/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.0717 - acc: 0.3230 - val_loss: 2.0395 - val_acc: 0.3348\n",
      "\n",
      "Epoch 00197: val_acc did not improve\n",
      "Epoch 198/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0745 - acc: 0.3206 - val_loss: 2.0400 - val_acc: 0.3374\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.33531 to 0.33741, saving model to models/feature_network.h5\n",
      "Epoch 199/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0710 - acc: 0.3232 - val_loss: 2.0354 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00199: val_acc did not improve\n",
      "Epoch 200/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.0654 - acc: 0.3260 - val_loss: 2.0336 - val_acc: 0.3372\n",
      "\n",
      "Epoch 00200: val_acc did not improve\n",
      "Epoch 201/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0625 - acc: 0.3260 - val_loss: 2.0334 - val_acc: 0.3414\n",
      "\n",
      "Epoch 00201: val_acc improved from 0.33741 to 0.34143, saving model to models/feature_network.h5\n",
      "Epoch 202/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0618 - acc: 0.3267 - val_loss: 2.0311 - val_acc: 0.3371\n",
      "\n",
      "Epoch 00202: val_acc did not improve\n",
      "Epoch 203/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0592 - acc: 0.3280 - val_loss: 2.0269 - val_acc: 0.3397\n",
      "\n",
      "Epoch 00203: val_acc did not improve\n",
      "Epoch 204/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0538 - acc: 0.3287 - val_loss: 2.0252 - val_acc: 0.3407\n",
      "\n",
      "Epoch 00204: val_acc did not improve\n",
      "Epoch 205/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0547 - acc: 0.3274 - val_loss: 2.0225 - val_acc: 0.3413\n",
      "\n",
      "Epoch 00205: val_acc did not improve\n",
      "Epoch 206/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0517 - acc: 0.3329 - val_loss: 2.0204 - val_acc: 0.3414\n",
      "\n",
      "Epoch 00206: val_acc did not improve\n",
      "Epoch 207/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.0491 - acc: 0.3307 - val_loss: 2.0194 - val_acc: 0.3414\n",
      "\n",
      "Epoch 00207: val_acc did not improve\n",
      "Epoch 208/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0470 - acc: 0.3308 - val_loss: 2.0169 - val_acc: 0.3432\n",
      "\n",
      "Epoch 00208: val_acc improved from 0.34143 to 0.34318, saving model to models/feature_network.h5\n",
      "Epoch 209/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0430 - acc: 0.3316 - val_loss: 2.0142 - val_acc: 0.3444\n",
      "\n",
      "Epoch 00209: val_acc improved from 0.34318 to 0.34440, saving model to models/feature_network.h5\n",
      "Epoch 210/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0412 - acc: 0.3329 - val_loss: 2.0118 - val_acc: 0.3454\n",
      "\n",
      "Epoch 00210: val_acc improved from 0.34440 to 0.34545, saving model to models/feature_network.h5\n",
      "Epoch 211/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0399 - acc: 0.3329 - val_loss: 2.0097 - val_acc: 0.3444\n",
      "\n",
      "Epoch 00211: val_acc did not improve\n",
      "Epoch 212/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0394 - acc: 0.3355 - val_loss: 2.0083 - val_acc: 0.3493\n",
      "\n",
      "Epoch 00212: val_acc improved from 0.34545 to 0.34929, saving model to models/feature_network.h5\n",
      "Epoch 213/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0314 - acc: 0.3372 - val_loss: 2.0083 - val_acc: 0.3509\n",
      "\n",
      "Epoch 00213: val_acc improved from 0.34929 to 0.35086, saving model to models/feature_network.h5\n",
      "Epoch 214/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0331 - acc: 0.3370 - val_loss: 2.0035 - val_acc: 0.3470\n",
      "\n",
      "Epoch 00214: val_acc did not improve\n",
      "Epoch 215/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0318 - acc: 0.3366 - val_loss: 2.0031 - val_acc: 0.3475\n",
      "\n",
      "Epoch 00215: val_acc did not improve\n",
      "Epoch 216/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.0277 - acc: 0.3383 - val_loss: 2.0018 - val_acc: 0.3489\n",
      "\n",
      "Epoch 00216: val_acc did not improve\n",
      "Epoch 217/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 2.0208 - acc: 0.3383 - val_loss: 1.9975 - val_acc: 0.3481\n",
      "\n",
      "Epoch 00217: val_acc did not improve\n",
      "Epoch 218/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 2.0250 - acc: 0.3352 - val_loss: 1.9957 - val_acc: 0.3533\n",
      "\n",
      "Epoch 00218: val_acc improved from 0.35086 to 0.35331, saving model to models/feature_network.h5\n",
      "Epoch 219/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0222 - acc: 0.3401 - val_loss: 1.9953 - val_acc: 0.3549\n",
      "\n",
      "Epoch 00219: val_acc improved from 0.35331 to 0.35488, saving model to models/feature_network.h5\n",
      "Epoch 220/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 2.0188 - acc: 0.3424 - val_loss: 1.9926 - val_acc: 0.3552\n",
      "\n",
      "Epoch 00220: val_acc improved from 0.35488 to 0.35523, saving model to models/feature_network.h5\n",
      "Epoch 221/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0166 - acc: 0.3397 - val_loss: 1.9905 - val_acc: 0.3535\n",
      "\n",
      "Epoch 00221: val_acc did not improve\n",
      "Epoch 222/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0157 - acc: 0.3452 - val_loss: 1.9906 - val_acc: 0.3572\n",
      "\n",
      "Epoch 00222: val_acc improved from 0.35523 to 0.35716, saving model to models/feature_network.h5\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0141 - acc: 0.3453 - val_loss: 1.9866 - val_acc: 0.3577\n",
      "\n",
      "Epoch 00223: val_acc improved from 0.35716 to 0.35768, saving model to models/feature_network.h5\n",
      "Epoch 224/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 2.0087 - acc: 0.3432 - val_loss: 1.9848 - val_acc: 0.3572\n",
      "\n",
      "Epoch 00224: val_acc did not improve\n",
      "Epoch 225/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0096 - acc: 0.3443 - val_loss: 1.9816 - val_acc: 0.3584\n",
      "\n",
      "Epoch 00225: val_acc improved from 0.35768 to 0.35838, saving model to models/feature_network.h5\n",
      "Epoch 226/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 2.0047 - acc: 0.3461 - val_loss: 1.9814 - val_acc: 0.3563\n",
      "\n",
      "Epoch 00226: val_acc did not improve\n",
      "Epoch 227/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 2.0000 - acc: 0.3452 - val_loss: 1.9783 - val_acc: 0.3586\n",
      "\n",
      "Epoch 00227: val_acc improved from 0.35838 to 0.35855, saving model to models/feature_network.h5\n",
      "Epoch 228/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9989 - acc: 0.3439 - val_loss: 1.9774 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00228: val_acc did not improve\n",
      "Epoch 229/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9981 - acc: 0.3478 - val_loss: 1.9748 - val_acc: 0.3584\n",
      "\n",
      "Epoch 00229: val_acc did not improve\n",
      "Epoch 230/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9945 - acc: 0.3499 - val_loss: 1.9734 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00230: val_acc did not improve\n",
      "Epoch 231/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9959 - acc: 0.3453 - val_loss: 1.9711 - val_acc: 0.3600\n",
      "\n",
      "Epoch 00231: val_acc improved from 0.35855 to 0.35995, saving model to models/feature_network.h5\n",
      "Epoch 232/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9875 - acc: 0.3522 - val_loss: 1.9687 - val_acc: 0.3610\n",
      "\n",
      "Epoch 00232: val_acc improved from 0.35995 to 0.36100, saving model to models/feature_network.h5\n",
      "Epoch 233/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9860 - acc: 0.3494 - val_loss: 1.9673 - val_acc: 0.3626\n",
      "\n",
      "Epoch 00233: val_acc improved from 0.36100 to 0.36257, saving model to models/feature_network.h5\n",
      "Epoch 234/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.9844 - acc: 0.3539 - val_loss: 1.9654 - val_acc: 0.3612\n",
      "\n",
      "Epoch 00234: val_acc did not improve\n",
      "Epoch 235/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9799 - acc: 0.3533 - val_loss: 1.9652 - val_acc: 0.3622\n",
      "\n",
      "Epoch 00235: val_acc did not improve\n",
      "Epoch 236/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9820 - acc: 0.3526 - val_loss: 1.9634 - val_acc: 0.3619\n",
      "\n",
      "Epoch 00236: val_acc did not improve\n",
      "Epoch 237/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9765 - acc: 0.3525 - val_loss: 1.9610 - val_acc: 0.3608\n",
      "\n",
      "Epoch 00237: val_acc did not improve\n",
      "Epoch 238/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9764 - acc: 0.3535 - val_loss: 1.9577 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00238: val_acc improved from 0.36257 to 0.36362, saving model to models/feature_network.h5\n",
      "Epoch 239/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9795 - acc: 0.3535 - val_loss: 1.9560 - val_acc: 0.3631\n",
      "\n",
      "Epoch 00239: val_acc did not improve\n",
      "Epoch 240/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9740 - acc: 0.3548 - val_loss: 1.9537 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00240: val_acc improved from 0.36362 to 0.36414, saving model to models/feature_network.h5\n",
      "Epoch 241/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.9674 - acc: 0.3586 - val_loss: 1.9519 - val_acc: 0.3650\n",
      "\n",
      "Epoch 00241: val_acc improved from 0.36414 to 0.36502, saving model to models/feature_network.h5\n",
      "Epoch 242/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9701 - acc: 0.3552 - val_loss: 1.9537 - val_acc: 0.3680\n",
      "\n",
      "Epoch 00242: val_acc improved from 0.36502 to 0.36799, saving model to models/feature_network.h5\n",
      "Epoch 243/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9677 - acc: 0.3565 - val_loss: 1.9487 - val_acc: 0.3669\n",
      "\n",
      "Epoch 00243: val_acc did not improve\n",
      "Epoch 244/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9696 - acc: 0.3575 - val_loss: 1.9471 - val_acc: 0.3664\n",
      "\n",
      "Epoch 00244: val_acc did not improve\n",
      "Epoch 245/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9618 - acc: 0.3579 - val_loss: 1.9458 - val_acc: 0.3662\n",
      "\n",
      "Epoch 00245: val_acc did not improve\n",
      "Epoch 246/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9586 - acc: 0.3627 - val_loss: 1.9434 - val_acc: 0.3675\n",
      "\n",
      "Epoch 00246: val_acc did not improve\n",
      "Epoch 247/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9588 - acc: 0.3592 - val_loss: 1.9420 - val_acc: 0.3671\n",
      "\n",
      "Epoch 00247: val_acc did not improve\n",
      "Epoch 248/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9593 - acc: 0.3600 - val_loss: 1.9401 - val_acc: 0.3683\n",
      "\n",
      "Epoch 00248: val_acc improved from 0.36799 to 0.36834, saving model to models/feature_network.h5\n",
      "Epoch 249/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9558 - acc: 0.3602 - val_loss: 1.9383 - val_acc: 0.3727\n",
      "\n",
      "Epoch 00249: val_acc improved from 0.36834 to 0.37271, saving model to models/feature_network.h5\n",
      "Epoch 250/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.9490 - acc: 0.3637 - val_loss: 1.9360 - val_acc: 0.3706\n",
      "\n",
      "Epoch 00250: val_acc did not improve\n",
      "Epoch 251/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9527 - acc: 0.3631 - val_loss: 1.9342 - val_acc: 0.3697\n",
      "\n",
      "Epoch 00251: val_acc did not improve\n",
      "Epoch 252/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9471 - acc: 0.3646 - val_loss: 1.9344 - val_acc: 0.3678\n",
      "\n",
      "Epoch 00252: val_acc did not improve\n",
      "Epoch 253/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9456 - acc: 0.3643 - val_loss: 1.9312 - val_acc: 0.3718\n",
      "\n",
      "Epoch 00253: val_acc did not improve\n",
      "Epoch 254/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9412 - acc: 0.3664 - val_loss: 1.9306 - val_acc: 0.3704\n",
      "\n",
      "Epoch 00254: val_acc did not improve\n",
      "Epoch 255/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9427 - acc: 0.3652 - val_loss: 1.9281 - val_acc: 0.3710\n",
      "\n",
      "Epoch 00255: val_acc did not improve\n",
      "Epoch 256/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9393 - acc: 0.3639 - val_loss: 1.9263 - val_acc: 0.3732\n",
      "\n",
      "Epoch 00256: val_acc improved from 0.37271 to 0.37323, saving model to models/feature_network.h5\n",
      "Epoch 257/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9407 - acc: 0.3654 - val_loss: 1.9260 - val_acc: 0.3687\n",
      "\n",
      "Epoch 00257: val_acc did not improve\n",
      "Epoch 258/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9359 - acc: 0.3676 - val_loss: 1.9266 - val_acc: 0.3745\n",
      "\n",
      "Epoch 00258: val_acc improved from 0.37323 to 0.37445, saving model to models/feature_network.h5\n",
      "Epoch 259/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9345 - acc: 0.3658 - val_loss: 1.9229 - val_acc: 0.3725\n",
      "\n",
      "Epoch 00259: val_acc did not improve\n",
      "Epoch 260/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.9290 - acc: 0.3708 - val_loss: 1.9196 - val_acc: 0.3748\n",
      "\n",
      "Epoch 00260: val_acc improved from 0.37445 to 0.37480, saving model to models/feature_network.h5\n",
      "Epoch 261/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.9290 - acc: 0.3697 - val_loss: 1.9174 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00261: val_acc improved from 0.37480 to 0.37498, saving model to models/feature_network.h5\n",
      "Epoch 262/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9300 - acc: 0.3686 - val_loss: 1.9163 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00262: val_acc improved from 0.37498 to 0.37498, saving model to models/feature_network.h5\n",
      "Epoch 263/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9252 - acc: 0.3685 - val_loss: 1.9153 - val_acc: 0.3762\n",
      "\n",
      "Epoch 00263: val_acc improved from 0.37498 to 0.37620, saving model to models/feature_network.h5\n",
      "Epoch 264/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9223 - acc: 0.3712 - val_loss: 1.9143 - val_acc: 0.3755\n",
      "\n",
      "Epoch 00264: val_acc did not improve\n",
      "Epoch 265/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.9238 - acc: 0.3697 - val_loss: 1.9121 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00265: val_acc did not improve\n",
      "Epoch 266/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9170 - acc: 0.3718 - val_loss: 1.9111 - val_acc: 0.3772\n",
      "\n",
      "Epoch 00266: val_acc improved from 0.37620 to 0.37725, saving model to models/feature_network.h5\n",
      "Epoch 267/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.9236 - acc: 0.3720 - val_loss: 1.9112 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00267: val_acc did not improve\n",
      "Epoch 268/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.9163 - acc: 0.3718 - val_loss: 1.9104 - val_acc: 0.3757\n",
      "\n",
      "Epoch 00268: val_acc did not improve\n",
      "Epoch 269/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9137 - acc: 0.3756 - val_loss: 1.9072 - val_acc: 0.3783\n",
      "\n",
      "Epoch 00269: val_acc improved from 0.37725 to 0.37830, saving model to models/feature_network.h5\n",
      "Epoch 270/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9138 - acc: 0.3734 - val_loss: 1.9052 - val_acc: 0.3811\n",
      "\n",
      "Epoch 00270: val_acc improved from 0.37830 to 0.38109, saving model to models/feature_network.h5\n",
      "Epoch 271/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.9123 - acc: 0.3726 - val_loss: 1.9049 - val_acc: 0.3743\n",
      "\n",
      "Epoch 00271: val_acc did not improve\n",
      "Epoch 272/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.9076 - acc: 0.3749 - val_loss: 1.9016 - val_acc: 0.3820\n",
      "\n",
      "Epoch 00272: val_acc improved from 0.38109 to 0.38197, saving model to models/feature_network.h5\n",
      "Epoch 273/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.9077 - acc: 0.3727 - val_loss: 1.9007 - val_acc: 0.3806\n",
      "\n",
      "Epoch 00273: val_acc did not improve\n",
      "Epoch 274/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.9050 - acc: 0.3772 - val_loss: 1.8991 - val_acc: 0.3778\n",
      "\n",
      "Epoch 00274: val_acc did not improve\n",
      "Epoch 275/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9005 - acc: 0.3758 - val_loss: 1.8978 - val_acc: 0.3844\n",
      "\n",
      "Epoch 00275: val_acc improved from 0.38197 to 0.38441, saving model to models/feature_network.h5\n",
      "Epoch 276/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.9009 - acc: 0.3801 - val_loss: 1.8962 - val_acc: 0.3832\n",
      "\n",
      "Epoch 00276: val_acc did not improve\n",
      "Epoch 277/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8991 - acc: 0.3789 - val_loss: 1.8953 - val_acc: 0.3799\n",
      "\n",
      "Epoch 00277: val_acc did not improve\n",
      "Epoch 278/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8943 - acc: 0.3790 - val_loss: 1.8937 - val_acc: 0.3820\n",
      "\n",
      "Epoch 00278: val_acc did not improve\n",
      "Epoch 279/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8951 - acc: 0.3811 - val_loss: 1.8951 - val_acc: 0.3800\n",
      "\n",
      "Epoch 00279: val_acc did not improve\n",
      "Epoch 280/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.8965 - acc: 0.3781 - val_loss: 1.8902 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00280: val_acc did not improve\n",
      "Epoch 281/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8928 - acc: 0.3810 - val_loss: 1.8896 - val_acc: 0.3849\n",
      "\n",
      "Epoch 00281: val_acc improved from 0.38441 to 0.38494, saving model to models/feature_network.h5\n",
      "Epoch 282/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8892 - acc: 0.3797 - val_loss: 1.8875 - val_acc: 0.3869\n",
      "\n",
      "Epoch 00282: val_acc improved from 0.38494 to 0.38686, saving model to models/feature_network.h5\n",
      "Epoch 283/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8867 - acc: 0.3838 - val_loss: 1.8865 - val_acc: 0.3837\n",
      "\n",
      "Epoch 00283: val_acc did not improve\n",
      "Epoch 284/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8864 - acc: 0.3837 - val_loss: 1.8868 - val_acc: 0.3814\n",
      "\n",
      "Epoch 00284: val_acc did not improve\n",
      "Epoch 285/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.8777 - acc: 0.3853 - val_loss: 1.8840 - val_acc: 0.3851\n",
      "\n",
      "Epoch 00285: val_acc did not improve\n",
      "Epoch 286/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8829 - acc: 0.3843 - val_loss: 1.8834 - val_acc: 0.3856\n",
      "\n",
      "Epoch 00286: val_acc did not improve\n",
      "Epoch 287/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8763 - acc: 0.3844 - val_loss: 1.8804 - val_acc: 0.3853\n",
      "\n",
      "Epoch 00287: val_acc did not improve\n",
      "Epoch 288/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8781 - acc: 0.3838 - val_loss: 1.8800 - val_acc: 0.3874\n",
      "\n",
      "Epoch 00288: val_acc improved from 0.38686 to 0.38738, saving model to models/feature_network.h5\n",
      "Epoch 289/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8782 - acc: 0.3870 - val_loss: 1.8793 - val_acc: 0.3858\n",
      "\n",
      "Epoch 00289: val_acc did not improve\n",
      "Epoch 290/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8734 - acc: 0.3922 - val_loss: 1.8776 - val_acc: 0.3867\n",
      "\n",
      "Epoch 00290: val_acc did not improve\n",
      "Epoch 291/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8683 - acc: 0.3865 - val_loss: 1.8762 - val_acc: 0.3891\n",
      "\n",
      "Epoch 00291: val_acc improved from 0.38738 to 0.38913, saving model to models/feature_network.h5\n",
      "Epoch 292/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.8730 - acc: 0.3885 - val_loss: 1.8764 - val_acc: 0.3883\n",
      "\n",
      "Epoch 00292: val_acc did not improve\n",
      "Epoch 293/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8656 - acc: 0.3903 - val_loss: 1.8724 - val_acc: 0.3881\n",
      "\n",
      "Epoch 00293: val_acc did not improve\n",
      "Epoch 294/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8657 - acc: 0.3913 - val_loss: 1.8712 - val_acc: 0.3874\n",
      "\n",
      "Epoch 00294: val_acc did not improve\n",
      "Epoch 295/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8680 - acc: 0.3860 - val_loss: 1.8707 - val_acc: 0.3900\n",
      "\n",
      "Epoch 00295: val_acc improved from 0.38913 to 0.39001, saving model to models/feature_network.h5\n",
      "Epoch 296/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8637 - acc: 0.3916 - val_loss: 1.8686 - val_acc: 0.3888\n",
      "\n",
      "Epoch 00296: val_acc did not improve\n",
      "Epoch 297/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8580 - acc: 0.3923 - val_loss: 1.8688 - val_acc: 0.3890\n",
      "\n",
      "Epoch 00297: val_acc did not improve\n",
      "Epoch 298/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8592 - acc: 0.3916 - val_loss: 1.8665 - val_acc: 0.3898\n",
      "\n",
      "Epoch 00298: val_acc did not improve\n",
      "Epoch 299/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8611 - acc: 0.3899 - val_loss: 1.8656 - val_acc: 0.3918\n",
      "\n",
      "Epoch 00299: val_acc improved from 0.39001 to 0.39175, saving model to models/feature_network.h5\n",
      "Epoch 300/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8522 - acc: 0.3960 - val_loss: 1.8666 - val_acc: 0.3876\n",
      "\n",
      "Epoch 00300: val_acc did not improve\n",
      "Epoch 301/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8535 - acc: 0.3917 - val_loss: 1.8636 - val_acc: 0.3897\n",
      "\n",
      "Epoch 00301: val_acc did not improve\n",
      "Epoch 302/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8532 - acc: 0.3955 - val_loss: 1.8621 - val_acc: 0.3926\n",
      "\n",
      "Epoch 00302: val_acc improved from 0.39175 to 0.39263, saving model to models/feature_network.h5\n",
      "Epoch 303/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8538 - acc: 0.3932 - val_loss: 1.8598 - val_acc: 0.3916\n",
      "\n",
      "Epoch 00303: val_acc did not improve\n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8492 - acc: 0.3904 - val_loss: 1.8604 - val_acc: 0.3900\n",
      "\n",
      "Epoch 00304: val_acc did not improve\n",
      "Epoch 305/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8460 - acc: 0.3953 - val_loss: 1.8581 - val_acc: 0.3951\n",
      "\n",
      "Epoch 00305: val_acc improved from 0.39263 to 0.39507, saving model to models/feature_network.h5\n",
      "Epoch 306/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8457 - acc: 0.3964 - val_loss: 1.8578 - val_acc: 0.3925\n",
      "\n",
      "Epoch 00306: val_acc did not improve\n",
      "Epoch 307/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8439 - acc: 0.3950 - val_loss: 1.8550 - val_acc: 0.3942\n",
      "\n",
      "Epoch 00307: val_acc did not improve\n",
      "Epoch 308/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8401 - acc: 0.3973 - val_loss: 1.8551 - val_acc: 0.3925\n",
      "\n",
      "Epoch 00308: val_acc did not improve\n",
      "Epoch 309/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8391 - acc: 0.3978 - val_loss: 1.8536 - val_acc: 0.3949\n",
      "\n",
      "Epoch 00309: val_acc did not improve\n",
      "Epoch 310/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8404 - acc: 0.3989 - val_loss: 1.8524 - val_acc: 0.3938\n",
      "\n",
      "Epoch 00310: val_acc did not improve\n",
      "Epoch 311/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8371 - acc: 0.3985 - val_loss: 1.8514 - val_acc: 0.3949\n",
      "\n",
      "Epoch 00311: val_acc did not improve\n",
      "Epoch 312/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8362 - acc: 0.4016 - val_loss: 1.8500 - val_acc: 0.3935\n",
      "\n",
      "Epoch 00312: val_acc did not improve\n",
      "Epoch 313/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8347 - acc: 0.3990 - val_loss: 1.8487 - val_acc: 0.3937\n",
      "\n",
      "Epoch 00313: val_acc did not improve\n",
      "Epoch 314/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8340 - acc: 0.4010 - val_loss: 1.8484 - val_acc: 0.3954\n",
      "\n",
      "Epoch 00314: val_acc improved from 0.39507 to 0.39542, saving model to models/feature_network.h5\n",
      "Epoch 315/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8278 - acc: 0.3993 - val_loss: 1.8480 - val_acc: 0.3937\n",
      "\n",
      "Epoch 00315: val_acc did not improve\n",
      "Epoch 316/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8327 - acc: 0.3989 - val_loss: 1.8468 - val_acc: 0.3951\n",
      "\n",
      "Epoch 00316: val_acc did not improve\n",
      "Epoch 317/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8273 - acc: 0.3996 - val_loss: 1.8438 - val_acc: 0.3944\n",
      "\n",
      "Epoch 00317: val_acc did not improve\n",
      "Epoch 318/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8271 - acc: 0.3992 - val_loss: 1.8436 - val_acc: 0.3959\n",
      "\n",
      "Epoch 00318: val_acc improved from 0.39542 to 0.39595, saving model to models/feature_network.h5\n",
      "Epoch 319/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8240 - acc: 0.4049 - val_loss: 1.8449 - val_acc: 0.3937\n",
      "\n",
      "Epoch 00319: val_acc did not improve\n",
      "Epoch 320/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8240 - acc: 0.4012 - val_loss: 1.8427 - val_acc: 0.3940\n",
      "\n",
      "Epoch 00320: val_acc did not improve\n",
      "Epoch 321/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8210 - acc: 0.4013 - val_loss: 1.8419 - val_acc: 0.3942\n",
      "\n",
      "Epoch 00321: val_acc did not improve\n",
      "Epoch 322/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8191 - acc: 0.4060 - val_loss: 1.8396 - val_acc: 0.3984\n",
      "\n",
      "Epoch 00322: val_acc improved from 0.39595 to 0.39839, saving model to models/feature_network.h5\n",
      "Epoch 323/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8181 - acc: 0.4036 - val_loss: 1.8384 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00323: val_acc improved from 0.39839 to 0.39857, saving model to models/feature_network.h5\n",
      "Epoch 324/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8182 - acc: 0.4059 - val_loss: 1.8372 - val_acc: 0.3980\n",
      "\n",
      "Epoch 00324: val_acc did not improve\n",
      "Epoch 325/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8144 - acc: 0.4047 - val_loss: 1.8356 - val_acc: 0.3975\n",
      "\n",
      "Epoch 00325: val_acc did not improve\n",
      "Epoch 326/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8133 - acc: 0.4025 - val_loss: 1.8347 - val_acc: 0.3961\n",
      "\n",
      "Epoch 00326: val_acc did not improve\n",
      "Epoch 327/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8097 - acc: 0.4080 - val_loss: 1.8340 - val_acc: 0.3965\n",
      "\n",
      "Epoch 00327: val_acc did not improve\n",
      "Epoch 328/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.8104 - acc: 0.4067 - val_loss: 1.8328 - val_acc: 0.3973\n",
      "\n",
      "Epoch 00328: val_acc did not improve\n",
      "Epoch 329/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8099 - acc: 0.4058 - val_loss: 1.8322 - val_acc: 0.3994\n",
      "\n",
      "Epoch 00329: val_acc improved from 0.39857 to 0.39944, saving model to models/feature_network.h5\n",
      "Epoch 330/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.8055 - acc: 0.4086 - val_loss: 1.8316 - val_acc: 0.4015\n",
      "\n",
      "Epoch 00330: val_acc improved from 0.39944 to 0.40154, saving model to models/feature_network.h5\n",
      "Epoch 331/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.8060 - acc: 0.4050 - val_loss: 1.8301 - val_acc: 0.3989\n",
      "\n",
      "Epoch 00331: val_acc did not improve\n",
      "Epoch 332/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.8014 - acc: 0.4076 - val_loss: 1.8289 - val_acc: 0.4014\n",
      "\n",
      "Epoch 00332: val_acc did not improve\n",
      "Epoch 333/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7997 - acc: 0.4113 - val_loss: 1.8288 - val_acc: 0.4028\n",
      "\n",
      "Epoch 00333: val_acc improved from 0.40154 to 0.40276, saving model to models/feature_network.h5\n",
      "Epoch 334/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.7998 - acc: 0.4085 - val_loss: 1.8283 - val_acc: 0.4022\n",
      "\n",
      "Epoch 00334: val_acc did not improve\n",
      "Epoch 335/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7987 - acc: 0.4088 - val_loss: 1.8265 - val_acc: 0.4012\n",
      "\n",
      "Epoch 00335: val_acc did not improve\n",
      "Epoch 336/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7942 - acc: 0.4144 - val_loss: 1.8255 - val_acc: 0.3977\n",
      "\n",
      "Epoch 00336: val_acc did not improve\n",
      "Epoch 337/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7927 - acc: 0.4091 - val_loss: 1.8236 - val_acc: 0.4001\n",
      "\n",
      "Epoch 00337: val_acc did not improve\n",
      "Epoch 338/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.7928 - acc: 0.4116 - val_loss: 1.8234 - val_acc: 0.3979\n",
      "\n",
      "Epoch 00338: val_acc did not improve\n",
      "Epoch 339/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7942 - acc: 0.4138 - val_loss: 1.8229 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00339: val_acc did not improve\n",
      "Epoch 340/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7892 - acc: 0.4138 - val_loss: 1.8211 - val_acc: 0.4040\n",
      "\n",
      "Epoch 00340: val_acc improved from 0.40276 to 0.40398, saving model to models/feature_network.h5\n",
      "Epoch 341/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7881 - acc: 0.4132 - val_loss: 1.8241 - val_acc: 0.4001\n",
      "\n",
      "Epoch 00341: val_acc did not improve\n",
      "Epoch 342/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7911 - acc: 0.4099 - val_loss: 1.8200 - val_acc: 0.4022\n",
      "\n",
      "Epoch 00342: val_acc did not improve\n",
      "Epoch 343/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7892 - acc: 0.4135 - val_loss: 1.8178 - val_acc: 0.4008\n",
      "\n",
      "Epoch 00343: val_acc did not improve\n",
      "Epoch 344/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.7843 - acc: 0.4130 - val_loss: 1.8159 - val_acc: 0.4054\n",
      "\n",
      "Epoch 00344: val_acc improved from 0.40398 to 0.40538, saving model to models/feature_network.h5\n",
      "Epoch 345/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7849 - acc: 0.4119 - val_loss: 1.8162 - val_acc: 0.4049\n",
      "\n",
      "Epoch 00345: val_acc did not improve\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7807 - acc: 0.4154 - val_loss: 1.8150 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00346: val_acc did not improve\n",
      "Epoch 347/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7763 - acc: 0.4212 - val_loss: 1.8142 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00347: val_acc did not improve\n",
      "Epoch 348/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7792 - acc: 0.4173 - val_loss: 1.8133 - val_acc: 0.4057\n",
      "\n",
      "Epoch 00348: val_acc improved from 0.40538 to 0.40573, saving model to models/feature_network.h5\n",
      "Epoch 349/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.7782 - acc: 0.4188 - val_loss: 1.8130 - val_acc: 0.4050\n",
      "\n",
      "Epoch 00349: val_acc did not improve\n",
      "Epoch 350/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7763 - acc: 0.4182 - val_loss: 1.8120 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00350: val_acc did not improve\n",
      "Epoch 351/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7745 - acc: 0.4172 - val_loss: 1.8115 - val_acc: 0.4096\n",
      "\n",
      "Epoch 00351: val_acc improved from 0.40573 to 0.40958, saving model to models/feature_network.h5\n",
      "Epoch 352/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7751 - acc: 0.4158 - val_loss: 1.8101 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00352: val_acc did not improve\n",
      "Epoch 353/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7733 - acc: 0.4173 - val_loss: 1.8113 - val_acc: 0.4057\n",
      "\n",
      "Epoch 00353: val_acc did not improve\n",
      "Epoch 354/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7698 - acc: 0.4197 - val_loss: 1.8092 - val_acc: 0.4052\n",
      "\n",
      "Epoch 00354: val_acc did not improve\n",
      "Epoch 355/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7686 - acc: 0.4210 - val_loss: 1.8070 - val_acc: 0.4122\n",
      "\n",
      "Epoch 00355: val_acc improved from 0.40958 to 0.41220, saving model to models/feature_network.h5\n",
      "Epoch 356/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.7677 - acc: 0.4189 - val_loss: 1.8067 - val_acc: 0.4087\n",
      "\n",
      "Epoch 00356: val_acc did not improve\n",
      "Epoch 357/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7650 - acc: 0.4175 - val_loss: 1.8051 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00357: val_acc did not improve\n",
      "Epoch 358/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7628 - acc: 0.4213 - val_loss: 1.8040 - val_acc: 0.4115\n",
      "\n",
      "Epoch 00358: val_acc did not improve\n",
      "Epoch 359/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7640 - acc: 0.4182 - val_loss: 1.8071 - val_acc: 0.4103\n",
      "\n",
      "Epoch 00359: val_acc did not improve\n",
      "Epoch 360/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7578 - acc: 0.4237 - val_loss: 1.8028 - val_acc: 0.4070\n",
      "\n",
      "Epoch 00360: val_acc did not improve\n",
      "Epoch 361/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7649 - acc: 0.4184 - val_loss: 1.8016 - val_acc: 0.4098\n",
      "\n",
      "Epoch 00361: val_acc did not improve\n",
      "Epoch 362/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.7585 - acc: 0.4258 - val_loss: 1.7997 - val_acc: 0.4098\n",
      "\n",
      "Epoch 00362: val_acc did not improve\n",
      "Epoch 363/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7584 - acc: 0.4214 - val_loss: 1.8011 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00363: val_acc did not improve\n",
      "Epoch 364/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7544 - acc: 0.4243 - val_loss: 1.8014 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00364: val_acc did not improve\n",
      "Epoch 365/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7539 - acc: 0.4234 - val_loss: 1.7973 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00365: val_acc did not improve\n",
      "Epoch 00365: early stopping\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, Y_train, \n",
    "          epochs=epochs, batch_size=batch_size, \n",
    "          callbacks = [checkpoint], \n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = 365\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('feature_network.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32488 samples, validate on 5723 samples\n",
      "Epoch 366/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7494 - acc: 0.4253 - val_loss: 1.7998 - val_acc: 0.4094\n",
      "\n",
      "Epoch 00366: val_acc did not improve\n",
      "Epoch 367/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.7478 - acc: 0.4255 - val_loss: 1.7968 - val_acc: 0.4129\n",
      "\n",
      "Epoch 00367: val_acc improved from 0.41220 to 0.41290, saving model to models/feature_network.h5\n",
      "Epoch 368/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.7468 - acc: 0.4213 - val_loss: 1.7981 - val_acc: 0.4143\n",
      "\n",
      "Epoch 00368: val_acc improved from 0.41290 to 0.41429, saving model to models/feature_network.h5\n",
      "Epoch 369/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7491 - acc: 0.4256 - val_loss: 1.7964 - val_acc: 0.4120\n",
      "\n",
      "Epoch 00369: val_acc did not improve\n",
      "Epoch 370/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7500 - acc: 0.4264 - val_loss: 1.7951 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00370: val_acc did not improve\n",
      "Epoch 371/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7461 - acc: 0.4262 - val_loss: 1.7939 - val_acc: 0.4113\n",
      "\n",
      "Epoch 00371: val_acc did not improve\n",
      "Epoch 372/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.7431 - acc: 0.4299 - val_loss: 1.7963 - val_acc: 0.4068\n",
      "\n",
      "Epoch 00372: val_acc did not improve\n",
      "Epoch 373/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7427 - acc: 0.4315 - val_loss: 1.7917 - val_acc: 0.4120\n",
      "\n",
      "Epoch 00373: val_acc did not improve\n",
      "Epoch 374/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7388 - acc: 0.4303 - val_loss: 1.7914 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00374: val_acc improved from 0.41429 to 0.41464, saving model to models/feature_network.h5\n",
      "Epoch 375/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7393 - acc: 0.4273 - val_loss: 1.7901 - val_acc: 0.4125\n",
      "\n",
      "Epoch 00375: val_acc did not improve\n",
      "Epoch 376/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.7425 - acc: 0.4282 - val_loss: 1.7890 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00376: val_acc improved from 0.41464 to 0.41517, saving model to models/feature_network.h5\n",
      "Epoch 377/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7330 - acc: 0.4307 - val_loss: 1.7889 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00377: val_acc did not improve\n",
      "Epoch 378/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7331 - acc: 0.4273 - val_loss: 1.7875 - val_acc: 0.4155\n",
      "\n",
      "Epoch 00378: val_acc improved from 0.41517 to 0.41552, saving model to models/feature_network.h5\n",
      "Epoch 379/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7356 - acc: 0.4310 - val_loss: 1.7874 - val_acc: 0.4132\n",
      "\n",
      "Epoch 00379: val_acc did not improve\n",
      "Epoch 380/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.7310 - acc: 0.4334 - val_loss: 1.7878 - val_acc: 0.4120\n",
      "\n",
      "Epoch 00380: val_acc did not improve\n",
      "Epoch 381/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.7293 - acc: 0.4311 - val_loss: 1.7889 - val_acc: 0.4122\n",
      "\n",
      "Epoch 00381: val_acc did not improve\n",
      "Epoch 382/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7271 - acc: 0.4312 - val_loss: 1.7844 - val_acc: 0.4143\n",
      "\n",
      "Epoch 00382: val_acc did not improve\n",
      "Epoch 383/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.7261 - acc: 0.4347 - val_loss: 1.7855 - val_acc: 0.4139\n",
      "\n",
      "Epoch 00383: val_acc did not improve\n",
      "Epoch 384/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.7288 - acc: 0.4322 - val_loss: 1.7843 - val_acc: 0.4136\n",
      "\n",
      "Epoch 00384: val_acc did not improve\n",
      "Epoch 385/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.7260 - acc: 0.4344 - val_loss: 1.7836 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00385: val_acc did not improve\n",
      "Epoch 386/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.7231 - acc: 0.4354 - val_loss: 1.7853 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00386: val_acc did not improve\n",
      "Epoch 387/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.7214 - acc: 0.4311 - val_loss: 1.7815 - val_acc: 0.4122\n",
      "\n",
      "Epoch 00387: val_acc did not improve\n",
      "Epoch 388/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.7214 - acc: 0.4360 - val_loss: 1.7812 - val_acc: 0.4153\n",
      "\n",
      "Epoch 00388: val_acc did not improve\n",
      "Epoch 389/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.7260 - acc: 0.4349 - val_loss: 1.7800 - val_acc: 0.4136\n",
      "\n",
      "Epoch 00389: val_acc did not improve\n",
      "Epoch 390/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.7174 - acc: 0.4358 - val_loss: 1.7803 - val_acc: 0.4148\n",
      "\n",
      "Epoch 00390: val_acc did not improve\n",
      "Epoch 391/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7163 - acc: 0.4377 - val_loss: 1.7787 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00391: val_acc improved from 0.41552 to 0.41779, saving model to models/feature_network.h5\n",
      "Epoch 392/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7234 - acc: 0.4324 - val_loss: 1.7774 - val_acc: 0.4171\n",
      "\n",
      "Epoch 00392: val_acc did not improve\n",
      "Epoch 393/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7125 - acc: 0.4380 - val_loss: 1.7761 - val_acc: 0.4188\n",
      "\n",
      "Epoch 00393: val_acc improved from 0.41779 to 0.41884, saving model to models/feature_network.h5\n",
      "Epoch 394/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.7149 - acc: 0.4361 - val_loss: 1.7764 - val_acc: 0.4164\n",
      "\n",
      "Epoch 00394: val_acc did not improve\n",
      "Epoch 395/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.7088 - acc: 0.4384 - val_loss: 1.7740 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00395: val_acc did not improve\n",
      "Epoch 396/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.7109 - acc: 0.4379 - val_loss: 1.7731 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00396: val_acc did not improve\n",
      "Epoch 397/1000\n",
      "32488/32488 [==============================] - 20s 624us/step - loss: 1.7095 - acc: 0.4372 - val_loss: 1.7729 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00397: val_acc improved from 0.41884 to 0.41954, saving model to models/feature_network.h5\n",
      "Epoch 398/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.7033 - acc: 0.4434 - val_loss: 1.7727 - val_acc: 0.4181\n",
      "\n",
      "Epoch 00398: val_acc did not improve\n",
      "Epoch 399/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.7047 - acc: 0.4365 - val_loss: 1.7756 - val_acc: 0.4183\n",
      "\n",
      "Epoch 00399: val_acc did not improve\n",
      "Epoch 400/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.7027 - acc: 0.4406 - val_loss: 1.7700 - val_acc: 0.4202\n",
      "\n",
      "Epoch 00400: val_acc improved from 0.41954 to 0.42023, saving model to models/feature_network.h5\n",
      "Epoch 401/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.7023 - acc: 0.4403 - val_loss: 1.7725 - val_acc: 0.4190\n",
      "\n",
      "Epoch 00401: val_acc did not improve\n",
      "Epoch 402/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.7038 - acc: 0.4395 - val_loss: 1.7691 - val_acc: 0.4208\n",
      "\n",
      "Epoch 00402: val_acc improved from 0.42023 to 0.42076, saving model to models/feature_network.h5\n",
      "Epoch 403/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6997 - acc: 0.4420 - val_loss: 1.7690 - val_acc: 0.4218\n",
      "\n",
      "Epoch 00403: val_acc improved from 0.42076 to 0.42181, saving model to models/feature_network.h5\n",
      "Epoch 404/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.6961 - acc: 0.4399 - val_loss: 1.7685 - val_acc: 0.4211\n",
      "\n",
      "Epoch 00404: val_acc did not improve\n",
      "Epoch 405/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.6982 - acc: 0.4429 - val_loss: 1.7685 - val_acc: 0.4197\n",
      "\n",
      "Epoch 00405: val_acc did not improve\n",
      "Epoch 406/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.6969 - acc: 0.4414 - val_loss: 1.7683 - val_acc: 0.4166\n",
      "\n",
      "Epoch 00406: val_acc did not improve\n",
      "Epoch 407/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6980 - acc: 0.4427 - val_loss: 1.7671 - val_acc: 0.4216\n",
      "\n",
      "Epoch 00407: val_acc did not improve\n",
      "Epoch 408/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.6987 - acc: 0.4431 - val_loss: 1.7691 - val_acc: 0.4223\n",
      "\n",
      "Epoch 00408: val_acc improved from 0.42181 to 0.42233, saving model to models/feature_network.h5\n",
      "Epoch 409/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6922 - acc: 0.4441 - val_loss: 1.7687 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00409: val_acc did not improve\n",
      "Epoch 410/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6890 - acc: 0.4408 - val_loss: 1.7668 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00410: val_acc did not improve\n",
      "Epoch 411/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.6926 - acc: 0.4425 - val_loss: 1.7677 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00411: val_acc did not improve\n",
      "Epoch 412/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6881 - acc: 0.4417 - val_loss: 1.7630 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00412: val_acc did not improve\n",
      "Epoch 413/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.6813 - acc: 0.4456 - val_loss: 1.7650 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00413: val_acc did not improve\n",
      "Epoch 414/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6871 - acc: 0.4416 - val_loss: 1.7638 - val_acc: 0.4183\n",
      "\n",
      "Epoch 00414: val_acc did not improve\n",
      "Epoch 415/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6851 - acc: 0.4461 - val_loss: 1.7647 - val_acc: 0.4225\n",
      "\n",
      "Epoch 00415: val_acc improved from 0.42233 to 0.42251, saving model to models/feature_network.h5\n",
      "Epoch 416/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.6802 - acc: 0.4484 - val_loss: 1.7635 - val_acc: 0.4237\n",
      "\n",
      "Epoch 00416: val_acc improved from 0.42251 to 0.42373, saving model to models/feature_network.h5\n",
      "Epoch 417/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.6797 - acc: 0.4455 - val_loss: 1.7629 - val_acc: 0.4244\n",
      "\n",
      "Epoch 00417: val_acc improved from 0.42373 to 0.42443, saving model to models/feature_network.h5\n",
      "Epoch 418/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6821 - acc: 0.4470 - val_loss: 1.7600 - val_acc: 0.4248\n",
      "\n",
      "Epoch 00418: val_acc improved from 0.42443 to 0.42478, saving model to models/feature_network.h5\n",
      "Epoch 419/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6759 - acc: 0.4452 - val_loss: 1.7579 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00419: val_acc did not improve\n",
      "Epoch 420/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.6812 - acc: 0.4450 - val_loss: 1.7577 - val_acc: 0.4241\n",
      "\n",
      "Epoch 00420: val_acc did not improve\n",
      "Epoch 421/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.6794 - acc: 0.4472 - val_loss: 1.7566 - val_acc: 0.4257\n",
      "\n",
      "Epoch 00421: val_acc improved from 0.42478 to 0.42565, saving model to models/feature_network.h5\n",
      "Epoch 422/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.6748 - acc: 0.4485 - val_loss: 1.7565 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00422: val_acc did not improve\n",
      "Epoch 423/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.6749 - acc: 0.4463 - val_loss: 1.7557 - val_acc: 0.4257\n",
      "\n",
      "Epoch 00423: val_acc did not improve\n",
      "Epoch 424/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6716 - acc: 0.4516 - val_loss: 1.7589 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00424: val_acc did not improve\n",
      "Epoch 425/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.6777 - acc: 0.4468 - val_loss: 1.7555 - val_acc: 0.4270\n",
      "\n",
      "Epoch 00425: val_acc improved from 0.42565 to 0.42705, saving model to models/feature_network.h5\n",
      "Epoch 426/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.6728 - acc: 0.4504 - val_loss: 1.7533 - val_acc: 0.4283\n",
      "\n",
      "Epoch 00426: val_acc improved from 0.42705 to 0.42827, saving model to models/feature_network.h5\n",
      "Epoch 427/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.6660 - acc: 0.4492 - val_loss: 1.7536 - val_acc: 0.4239\n",
      "\n",
      "Epoch 00427: val_acc did not improve\n",
      "Epoch 428/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.6725 - acc: 0.4480 - val_loss: 1.7529 - val_acc: 0.4239\n",
      "\n",
      "Epoch 00428: val_acc did not improve\n",
      "Epoch 429/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6639 - acc: 0.4523 - val_loss: 1.7509 - val_acc: 0.4269\n",
      "\n",
      "Epoch 00429: val_acc did not improve\n",
      "Epoch 430/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.6659 - acc: 0.4506 - val_loss: 1.7512 - val_acc: 0.4269\n",
      "\n",
      "Epoch 00430: val_acc did not improve\n",
      "Epoch 431/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6636 - acc: 0.4508 - val_loss: 1.7505 - val_acc: 0.4253\n",
      "\n",
      "Epoch 00431: val_acc did not improve\n",
      "Epoch 432/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.6629 - acc: 0.4545 - val_loss: 1.7506 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00432: val_acc did not improve\n",
      "Epoch 433/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6648 - acc: 0.4528 - val_loss: 1.7492 - val_acc: 0.4276\n",
      "\n",
      "Epoch 00433: val_acc did not improve\n",
      "Epoch 434/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.6563 - acc: 0.4529 - val_loss: 1.7503 - val_acc: 0.4269\n",
      "\n",
      "Epoch 00434: val_acc did not improve\n",
      "Epoch 435/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.6568 - acc: 0.4525 - val_loss: 1.7508 - val_acc: 0.4244\n",
      "\n",
      "Epoch 00435: val_acc did not improve\n",
      "Epoch 436/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6532 - acc: 0.4554 - val_loss: 1.7477 - val_acc: 0.4276\n",
      "\n",
      "Epoch 00436: val_acc did not improve\n",
      "Epoch 437/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.6555 - acc: 0.4571 - val_loss: 1.7488 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00437: val_acc did not improve\n",
      "Epoch 438/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.6523 - acc: 0.4549 - val_loss: 1.7467 - val_acc: 0.4298\n",
      "\n",
      "Epoch 00438: val_acc improved from 0.42827 to 0.42984, saving model to models/feature_network.h5\n",
      "Epoch 439/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.6502 - acc: 0.4550 - val_loss: 1.7459 - val_acc: 0.4295\n",
      "\n",
      "Epoch 00439: val_acc did not improve\n",
      "Epoch 440/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.6516 - acc: 0.4521 - val_loss: 1.7457 - val_acc: 0.4304\n",
      "\n",
      "Epoch 00440: val_acc improved from 0.42984 to 0.43037, saving model to models/feature_network.h5\n",
      "Epoch 441/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.6503 - acc: 0.4584 - val_loss: 1.7445 - val_acc: 0.4276\n",
      "\n",
      "Epoch 00441: val_acc did not improve\n",
      "Epoch 442/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6512 - acc: 0.4574 - val_loss: 1.7445 - val_acc: 0.4305\n",
      "\n",
      "Epoch 00442: val_acc improved from 0.43037 to 0.43054, saving model to models/feature_network.h5\n",
      "Epoch 443/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6460 - acc: 0.4585 - val_loss: 1.7447 - val_acc: 0.4279\n",
      "\n",
      "Epoch 00443: val_acc did not improve\n",
      "Epoch 444/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6454 - acc: 0.4603 - val_loss: 1.7427 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00444: val_acc did not improve\n",
      "Epoch 445/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6441 - acc: 0.4562 - val_loss: 1.7424 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00445: val_acc did not improve\n",
      "Epoch 446/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6474 - acc: 0.4603 - val_loss: 1.7432 - val_acc: 0.4291\n",
      "\n",
      "Epoch 00446: val_acc did not improve\n",
      "Epoch 447/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6444 - acc: 0.4596 - val_loss: 1.7416 - val_acc: 0.4309\n",
      "\n",
      "Epoch 00447: val_acc improved from 0.43054 to 0.43089, saving model to models/feature_network.h5\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6439 - acc: 0.4587 - val_loss: 1.7409 - val_acc: 0.4277\n",
      "\n",
      "Epoch 00448: val_acc did not improve\n",
      "Epoch 449/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6393 - acc: 0.4592 - val_loss: 1.7403 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00449: val_acc did not improve\n",
      "Epoch 450/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6376 - acc: 0.4573 - val_loss: 1.7391 - val_acc: 0.4314\n",
      "\n",
      "Epoch 00450: val_acc improved from 0.43089 to 0.43142, saving model to models/feature_network.h5\n",
      "Epoch 451/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6398 - acc: 0.4582 - val_loss: 1.7384 - val_acc: 0.4311\n",
      "\n",
      "Epoch 00451: val_acc did not improve\n",
      "Epoch 452/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.6409 - acc: 0.4590 - val_loss: 1.7406 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00452: val_acc did not improve\n",
      "Epoch 453/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.6385 - acc: 0.4612 - val_loss: 1.7383 - val_acc: 0.4283\n",
      "\n",
      "Epoch 00453: val_acc did not improve\n",
      "Epoch 454/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6323 - acc: 0.4608 - val_loss: 1.7409 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00454: val_acc did not improve\n",
      "Epoch 455/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6292 - acc: 0.4641 - val_loss: 1.7363 - val_acc: 0.4319\n",
      "\n",
      "Epoch 00455: val_acc improved from 0.43142 to 0.43194, saving model to models/feature_network.h5\n",
      "Epoch 456/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.6322 - acc: 0.4617 - val_loss: 1.7371 - val_acc: 0.4339\n",
      "\n",
      "Epoch 00456: val_acc improved from 0.43194 to 0.43386, saving model to models/feature_network.h5\n",
      "Epoch 457/1000\n",
      "32488/32488 [==============================] - 20s 625us/step - loss: 1.6277 - acc: 0.4624 - val_loss: 1.7362 - val_acc: 0.4307\n",
      "\n",
      "Epoch 00457: val_acc did not improve\n",
      "Epoch 458/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.6328 - acc: 0.4607 - val_loss: 1.7341 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00458: val_acc did not improve\n",
      "Epoch 459/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.6266 - acc: 0.4631 - val_loss: 1.7357 - val_acc: 0.4305\n",
      "\n",
      "Epoch 00459: val_acc did not improve\n",
      "Epoch 460/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6256 - acc: 0.4613 - val_loss: 1.7330 - val_acc: 0.4344\n",
      "\n",
      "Epoch 00460: val_acc improved from 0.43386 to 0.43439, saving model to models/feature_network.h5\n",
      "Epoch 461/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.6224 - acc: 0.4624 - val_loss: 1.7347 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00461: val_acc did not improve\n",
      "Epoch 462/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6200 - acc: 0.4659 - val_loss: 1.7333 - val_acc: 0.4305\n",
      "\n",
      "Epoch 00462: val_acc did not improve\n",
      "Epoch 463/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.6215 - acc: 0.4658 - val_loss: 1.7321 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00463: val_acc did not improve\n",
      "Epoch 464/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.6168 - acc: 0.4665 - val_loss: 1.7313 - val_acc: 0.4346\n",
      "\n",
      "Epoch 00464: val_acc improved from 0.43439 to 0.43456, saving model to models/feature_network.h5\n",
      "Epoch 465/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.6210 - acc: 0.4646 - val_loss: 1.7305 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00465: val_acc did not improve\n",
      "Epoch 466/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.6178 - acc: 0.4660 - val_loss: 1.7292 - val_acc: 0.4321\n",
      "\n",
      "Epoch 00466: val_acc did not improve\n",
      "Epoch 467/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.6146 - acc: 0.4659 - val_loss: 1.7290 - val_acc: 0.4365\n",
      "\n",
      "Epoch 00467: val_acc improved from 0.43456 to 0.43648, saving model to models/feature_network.h5\n",
      "Epoch 468/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6127 - acc: 0.4667 - val_loss: 1.7276 - val_acc: 0.4349\n",
      "\n",
      "Epoch 00468: val_acc did not improve\n",
      "Epoch 469/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.6157 - acc: 0.4667 - val_loss: 1.7273 - val_acc: 0.4346\n",
      "\n",
      "Epoch 00469: val_acc did not improve\n",
      "Epoch 470/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.6161 - acc: 0.4667 - val_loss: 1.7293 - val_acc: 0.4353\n",
      "\n",
      "Epoch 00470: val_acc did not improve\n",
      "Epoch 471/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.6144 - acc: 0.4687 - val_loss: 1.7262 - val_acc: 0.4318\n",
      "\n",
      "Epoch 00471: val_acc did not improve\n",
      "Epoch 472/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.6126 - acc: 0.4686 - val_loss: 1.7280 - val_acc: 0.4349\n",
      "\n",
      "Epoch 00472: val_acc did not improve\n",
      "Epoch 473/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.6102 - acc: 0.4679 - val_loss: 1.7258 - val_acc: 0.4326\n",
      "\n",
      "Epoch 00473: val_acc did not improve\n",
      "Epoch 474/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.6100 - acc: 0.4683 - val_loss: 1.7275 - val_acc: 0.4333\n",
      "\n",
      "Epoch 00474: val_acc did not improve\n",
      "Epoch 475/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.6056 - acc: 0.4678 - val_loss: 1.7237 - val_acc: 0.4349\n",
      "\n",
      "Epoch 00475: val_acc did not improve\n",
      "Epoch 476/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6066 - acc: 0.4713 - val_loss: 1.7247 - val_acc: 0.4328\n",
      "\n",
      "Epoch 00476: val_acc did not improve\n",
      "Epoch 477/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.6029 - acc: 0.4723 - val_loss: 1.7249 - val_acc: 0.4358\n",
      "\n",
      "Epoch 00477: val_acc did not improve\n",
      "Epoch 478/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.5990 - acc: 0.4679 - val_loss: 1.7237 - val_acc: 0.4339\n",
      "\n",
      "Epoch 00478: val_acc did not improve\n",
      "Epoch 479/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.6020 - acc: 0.4703 - val_loss: 1.7242 - val_acc: 0.4353\n",
      "\n",
      "Epoch 00479: val_acc did not improve\n",
      "Epoch 480/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.6057 - acc: 0.4699 - val_loss: 1.7222 - val_acc: 0.4356\n",
      "\n",
      "Epoch 00480: val_acc did not improve\n",
      "Epoch 481/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.6025 - acc: 0.4709 - val_loss: 1.7211 - val_acc: 0.4367\n",
      "\n",
      "Epoch 00481: val_acc improved from 0.43648 to 0.43666, saving model to models/feature_network.h5\n",
      "Epoch 482/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.5958 - acc: 0.4726 - val_loss: 1.7220 - val_acc: 0.4367\n",
      "\n",
      "Epoch 00482: val_acc did not improve\n",
      "Epoch 483/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.5979 - acc: 0.4721 - val_loss: 1.7221 - val_acc: 0.4356\n",
      "\n",
      "Epoch 00483: val_acc did not improve\n",
      "Epoch 484/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5939 - acc: 0.4750 - val_loss: 1.7209 - val_acc: 0.4360\n",
      "\n",
      "Epoch 00484: val_acc did not improve\n",
      "Epoch 485/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5921 - acc: 0.4722 - val_loss: 1.7227 - val_acc: 0.4344\n",
      "\n",
      "Epoch 00485: val_acc did not improve\n",
      "Epoch 486/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5913 - acc: 0.4742 - val_loss: 1.7214 - val_acc: 0.4344\n",
      "\n",
      "Epoch 00486: val_acc did not improve\n",
      "Epoch 487/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.5923 - acc: 0.4750 - val_loss: 1.7193 - val_acc: 0.4344\n",
      "\n",
      "Epoch 00487: val_acc did not improve\n",
      "Epoch 488/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.5918 - acc: 0.4733 - val_loss: 1.7167 - val_acc: 0.4379\n",
      "\n",
      "Epoch 00488: val_acc improved from 0.43666 to 0.43788, saving model to models/feature_network.h5\n",
      "Epoch 489/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.5934 - acc: 0.4727 - val_loss: 1.7168 - val_acc: 0.4363\n",
      "\n",
      "Epoch 00489: val_acc did not improve\n",
      "Epoch 490/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5881 - acc: 0.4762 - val_loss: 1.7161 - val_acc: 0.4368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00490: val_acc did not improve\n",
      "Epoch 491/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5927 - acc: 0.4748 - val_loss: 1.7177 - val_acc: 0.4379\n",
      "\n",
      "Epoch 00491: val_acc did not improve\n",
      "Epoch 492/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.5853 - acc: 0.4717 - val_loss: 1.7189 - val_acc: 0.4351\n",
      "\n",
      "Epoch 00492: val_acc did not improve\n",
      "Epoch 493/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5883 - acc: 0.4767 - val_loss: 1.7154 - val_acc: 0.4367\n",
      "\n",
      "Epoch 00493: val_acc did not improve\n",
      "Epoch 494/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5815 - acc: 0.4767 - val_loss: 1.7147 - val_acc: 0.4388\n",
      "\n",
      "Epoch 00494: val_acc improved from 0.43788 to 0.43876, saving model to models/feature_network.h5\n",
      "Epoch 495/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5799 - acc: 0.4772 - val_loss: 1.7180 - val_acc: 0.4346\n",
      "\n",
      "Epoch 00495: val_acc did not improve\n",
      "Epoch 496/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5810 - acc: 0.4756 - val_loss: 1.7164 - val_acc: 0.4360\n",
      "\n",
      "Epoch 00496: val_acc did not improve\n",
      "Epoch 497/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5774 - acc: 0.4749 - val_loss: 1.7147 - val_acc: 0.4377\n",
      "\n",
      "Epoch 00497: val_acc did not improve\n",
      "Epoch 498/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5770 - acc: 0.4769 - val_loss: 1.7139 - val_acc: 0.4374\n",
      "\n",
      "Epoch 00498: val_acc did not improve\n",
      "Epoch 499/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5759 - acc: 0.4805 - val_loss: 1.7131 - val_acc: 0.4370\n",
      "\n",
      "Epoch 00499: val_acc did not improve\n",
      "Epoch 500/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5765 - acc: 0.4811 - val_loss: 1.7151 - val_acc: 0.4360\n",
      "\n",
      "Epoch 00500: val_acc did not improve\n",
      "Epoch 501/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5750 - acc: 0.4803 - val_loss: 1.7119 - val_acc: 0.4389\n",
      "\n",
      "Epoch 00501: val_acc improved from 0.43876 to 0.43893, saving model to models/feature_network.h5\n",
      "Epoch 502/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5714 - acc: 0.4829 - val_loss: 1.7113 - val_acc: 0.4395\n",
      "\n",
      "Epoch 00502: val_acc improved from 0.43893 to 0.43945, saving model to models/feature_network.h5\n",
      "Epoch 503/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5704 - acc: 0.4826 - val_loss: 1.7097 - val_acc: 0.4384\n",
      "\n",
      "Epoch 00503: val_acc did not improve\n",
      "Epoch 504/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5727 - acc: 0.4818 - val_loss: 1.7096 - val_acc: 0.4419\n",
      "\n",
      "Epoch 00504: val_acc improved from 0.43945 to 0.44190, saving model to models/feature_network.h5\n",
      "Epoch 505/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5647 - acc: 0.4831 - val_loss: 1.7091 - val_acc: 0.4398\n",
      "\n",
      "Epoch 00505: val_acc did not improve\n",
      "Epoch 506/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.5679 - acc: 0.4845 - val_loss: 1.7111 - val_acc: 0.4384\n",
      "\n",
      "Epoch 00506: val_acc did not improve\n",
      "Epoch 507/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5652 - acc: 0.4815 - val_loss: 1.7086 - val_acc: 0.4419\n",
      "\n",
      "Epoch 00507: val_acc did not improve\n",
      "Epoch 508/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.5663 - acc: 0.4838 - val_loss: 1.7078 - val_acc: 0.4382\n",
      "\n",
      "Epoch 00508: val_acc did not improve\n",
      "Epoch 509/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.5644 - acc: 0.4811 - val_loss: 1.7122 - val_acc: 0.4374\n",
      "\n",
      "Epoch 00509: val_acc did not improve\n",
      "Epoch 510/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5638 - acc: 0.4853 - val_loss: 1.7064 - val_acc: 0.4407\n",
      "\n",
      "Epoch 00510: val_acc did not improve\n",
      "Epoch 511/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.5621 - acc: 0.4831 - val_loss: 1.7066 - val_acc: 0.4398\n",
      "\n",
      "Epoch 00511: val_acc did not improve\n",
      "Epoch 512/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.5601 - acc: 0.4819 - val_loss: 1.7075 - val_acc: 0.4424\n",
      "\n",
      "Epoch 00512: val_acc improved from 0.44190 to 0.44243, saving model to models/feature_network.h5\n",
      "Epoch 513/1000\n",
      "32488/32488 [==============================] - 20s 630us/step - loss: 1.5546 - acc: 0.4859 - val_loss: 1.7064 - val_acc: 0.4410\n",
      "\n",
      "Epoch 00513: val_acc did not improve\n",
      "Epoch 514/1000\n",
      "32488/32488 [==============================] - 22s 668us/step - loss: 1.5586 - acc: 0.4835 - val_loss: 1.7044 - val_acc: 0.4403\n",
      "\n",
      "Epoch 00514: val_acc did not improve\n",
      "Epoch 515/1000\n",
      "32488/32488 [==============================] - 21s 639us/step - loss: 1.5560 - acc: 0.4845 - val_loss: 1.7081 - val_acc: 0.4382\n",
      "\n",
      "Epoch 00515: val_acc did not improve\n",
      "Epoch 516/1000\n",
      "32488/32488 [==============================] - 21s 656us/step - loss: 1.5542 - acc: 0.4843 - val_loss: 1.7064 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00516: val_acc did not improve\n",
      "Epoch 517/1000\n",
      "32488/32488 [==============================] - 21s 648us/step - loss: 1.5524 - acc: 0.4877 - val_loss: 1.7043 - val_acc: 0.4395\n",
      "\n",
      "Epoch 00517: val_acc did not improve\n",
      "Epoch 518/1000\n",
      "32488/32488 [==============================] - 21s 657us/step - loss: 1.5526 - acc: 0.4879 - val_loss: 1.7018 - val_acc: 0.4419\n",
      "\n",
      "Epoch 00518: val_acc did not improve\n",
      "Epoch 519/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.5535 - acc: 0.4837 - val_loss: 1.7024 - val_acc: 0.4407\n",
      "\n",
      "Epoch 00519: val_acc did not improve\n",
      "Epoch 520/1000\n",
      "32488/32488 [==============================] - 20s 628us/step - loss: 1.5501 - acc: 0.4843 - val_loss: 1.7038 - val_acc: 0.4421\n",
      "\n",
      "Epoch 00520: val_acc did not improve\n",
      "Epoch 521/1000\n",
      "32488/32488 [==============================] - 21s 638us/step - loss: 1.5519 - acc: 0.4848 - val_loss: 1.7023 - val_acc: 0.4414\n",
      "\n",
      "Epoch 00521: val_acc did not improve\n",
      "Epoch 522/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.5495 - acc: 0.4880 - val_loss: 1.7025 - val_acc: 0.4395\n",
      "\n",
      "Epoch 00522: val_acc did not improve\n",
      "Epoch 523/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.5477 - acc: 0.4890 - val_loss: 1.7005 - val_acc: 0.4410\n",
      "\n",
      "Epoch 00523: val_acc did not improve\n",
      "Epoch 524/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.5440 - acc: 0.4879 - val_loss: 1.7030 - val_acc: 0.4426\n",
      "\n",
      "Epoch 00524: val_acc improved from 0.44243 to 0.44260, saving model to models/feature_network.h5\n",
      "Epoch 525/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.5478 - acc: 0.4860 - val_loss: 1.7014 - val_acc: 0.4416\n",
      "\n",
      "Epoch 00525: val_acc did not improve\n",
      "Epoch 526/1000\n",
      "32488/32488 [==============================] - 20s 628us/step - loss: 1.5434 - acc: 0.4910 - val_loss: 1.6993 - val_acc: 0.4435\n",
      "\n",
      "Epoch 00526: val_acc improved from 0.44260 to 0.44347, saving model to models/feature_network.h5\n",
      "Epoch 527/1000\n",
      "32488/32488 [==============================] - 20s 624us/step - loss: 1.5408 - acc: 0.4869 - val_loss: 1.6994 - val_acc: 0.4440\n",
      "\n",
      "Epoch 00527: val_acc improved from 0.44347 to 0.44400, saving model to models/feature_network.h5\n",
      "Epoch 528/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5408 - acc: 0.4890 - val_loss: 1.7004 - val_acc: 0.4421\n",
      "\n",
      "Epoch 00528: val_acc did not improve\n",
      "Epoch 529/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5416 - acc: 0.4894 - val_loss: 1.7000 - val_acc: 0.4423\n",
      "\n",
      "Epoch 00529: val_acc did not improve\n",
      "Epoch 530/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.5361 - acc: 0.4928 - val_loss: 1.6963 - val_acc: 0.4419\n",
      "\n",
      "Epoch 00530: val_acc did not improve\n",
      "Epoch 531/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5397 - acc: 0.4904 - val_loss: 1.6976 - val_acc: 0.4424\n",
      "\n",
      "Epoch 00531: val_acc did not improve\n",
      "Epoch 532/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5358 - acc: 0.4911 - val_loss: 1.7052 - val_acc: 0.4416\n",
      "\n",
      "Epoch 00532: val_acc did not improve\n",
      "Epoch 533/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5354 - acc: 0.4871 - val_loss: 1.6982 - val_acc: 0.4417\n",
      "\n",
      "Epoch 00533: val_acc did not improve\n",
      "Epoch 534/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5336 - acc: 0.4865 - val_loss: 1.6965 - val_acc: 0.4454\n",
      "\n",
      "Epoch 00534: val_acc improved from 0.44400 to 0.44540, saving model to models/feature_network.h5\n",
      "Epoch 535/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5326 - acc: 0.4935 - val_loss: 1.6964 - val_acc: 0.4407\n",
      "\n",
      "Epoch 00535: val_acc did not improve\n",
      "Epoch 536/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.5304 - acc: 0.4925 - val_loss: 1.6952 - val_acc: 0.4443\n",
      "\n",
      "Epoch 00536: val_acc did not improve\n",
      "Epoch 537/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.5336 - acc: 0.4908 - val_loss: 1.6966 - val_acc: 0.4436\n",
      "\n",
      "Epoch 00537: val_acc did not improve\n",
      "Epoch 538/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5313 - acc: 0.4935 - val_loss: 1.6944 - val_acc: 0.4470\n",
      "\n",
      "Epoch 00538: val_acc improved from 0.44540 to 0.44697, saving model to models/feature_network.h5\n",
      "Epoch 539/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5264 - acc: 0.4944 - val_loss: 1.6942 - val_acc: 0.4447\n",
      "\n",
      "Epoch 00539: val_acc did not improve\n",
      "Epoch 540/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5282 - acc: 0.4956 - val_loss: 1.6921 - val_acc: 0.4459\n",
      "\n",
      "Epoch 00540: val_acc did not improve\n",
      "Epoch 541/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.5232 - acc: 0.4975 - val_loss: 1.6937 - val_acc: 0.4454\n",
      "\n",
      "Epoch 00541: val_acc did not improve\n",
      "Epoch 542/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.5256 - acc: 0.4938 - val_loss: 1.6926 - val_acc: 0.4449\n",
      "\n",
      "Epoch 00542: val_acc did not improve\n",
      "Epoch 543/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5221 - acc: 0.4964 - val_loss: 1.6935 - val_acc: 0.4429\n",
      "\n",
      "Epoch 00543: val_acc did not improve\n",
      "Epoch 544/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5260 - acc: 0.4967 - val_loss: 1.6931 - val_acc: 0.4443\n",
      "\n",
      "Epoch 00544: val_acc did not improve\n",
      "Epoch 545/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.5183 - acc: 0.4961 - val_loss: 1.6912 - val_acc: 0.4431\n",
      "\n",
      "Epoch 00545: val_acc did not improve\n",
      "Epoch 546/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5255 - acc: 0.4918 - val_loss: 1.6903 - val_acc: 0.4426\n",
      "\n",
      "Epoch 00546: val_acc did not improve\n",
      "Epoch 547/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.5200 - acc: 0.4952 - val_loss: 1.6910 - val_acc: 0.4436\n",
      "\n",
      "Epoch 00547: val_acc did not improve\n",
      "Epoch 548/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5189 - acc: 0.4957 - val_loss: 1.6900 - val_acc: 0.4466\n",
      "\n",
      "Epoch 00548: val_acc did not improve\n",
      "Epoch 549/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5189 - acc: 0.5001 - val_loss: 1.6920 - val_acc: 0.4424\n",
      "\n",
      "Epoch 00549: val_acc did not improve\n",
      "Epoch 550/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5111 - acc: 0.4975 - val_loss: 1.6884 - val_acc: 0.4445\n",
      "\n",
      "Epoch 00550: val_acc did not improve\n",
      "Epoch 551/1000\n",
      "32488/32488 [==============================] - 20s 611us/step - loss: 1.5141 - acc: 0.4970 - val_loss: 1.6932 - val_acc: 0.4431\n",
      "\n",
      "Epoch 00551: val_acc did not improve\n",
      "Epoch 552/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5100 - acc: 0.4974 - val_loss: 1.6888 - val_acc: 0.4421\n",
      "\n",
      "Epoch 00552: val_acc did not improve\n",
      "Epoch 553/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5135 - acc: 0.5000 - val_loss: 1.6898 - val_acc: 0.4477\n",
      "\n",
      "Epoch 00553: val_acc improved from 0.44697 to 0.44767, saving model to models/feature_network.h5\n",
      "Epoch 554/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5085 - acc: 0.5005 - val_loss: 1.6884 - val_acc: 0.4431\n",
      "\n",
      "Epoch 00554: val_acc did not improve\n",
      "Epoch 555/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5081 - acc: 0.4987 - val_loss: 1.6890 - val_acc: 0.4459\n",
      "\n",
      "Epoch 00555: val_acc did not improve\n",
      "Epoch 556/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5076 - acc: 0.4973 - val_loss: 1.6931 - val_acc: 0.4396\n",
      "\n",
      "Epoch 00556: val_acc did not improve\n",
      "Epoch 557/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5041 - acc: 0.5009 - val_loss: 1.6861 - val_acc: 0.4428\n",
      "\n",
      "Epoch 00557: val_acc did not improve\n",
      "Epoch 558/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5080 - acc: 0.5004 - val_loss: 1.6849 - val_acc: 0.4468\n",
      "\n",
      "Epoch 00558: val_acc did not improve\n",
      "Epoch 559/1000\n",
      "32488/32488 [==============================] - 20s 613us/step - loss: 1.5061 - acc: 0.5014 - val_loss: 1.6880 - val_acc: 0.4433\n",
      "\n",
      "Epoch 00559: val_acc did not improve\n",
      "Epoch 560/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5014 - acc: 0.5036 - val_loss: 1.6852 - val_acc: 0.4456\n",
      "\n",
      "Epoch 00560: val_acc did not improve\n",
      "Epoch 561/1000\n",
      "32488/32488 [==============================] - 20s 612us/step - loss: 1.5029 - acc: 0.5012 - val_loss: 1.6855 - val_acc: 0.4484\n",
      "\n",
      "Epoch 00561: val_acc improved from 0.44767 to 0.44837, saving model to models/feature_network.h5\n",
      "Epoch 562/1000\n",
      "32488/32488 [==============================] - 20s 614us/step - loss: 1.4940 - acc: 0.5067 - val_loss: 1.6850 - val_acc: 0.4438\n",
      "\n",
      "Epoch 00562: val_acc did not improve\n",
      "Epoch 563/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.5051 - acc: 0.5006 - val_loss: 1.6830 - val_acc: 0.4471\n",
      "\n",
      "Epoch 00563: val_acc did not improve\n",
      "Epoch 564/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.4954 - acc: 0.5062 - val_loss: 1.6839 - val_acc: 0.4477\n",
      "\n",
      "Epoch 00564: val_acc did not improve\n",
      "Epoch 565/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.4979 - acc: 0.5034 - val_loss: 1.6866 - val_acc: 0.4506\n",
      "\n",
      "Epoch 00565: val_acc improved from 0.44837 to 0.45064, saving model to models/feature_network.h5\n",
      "Epoch 566/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4910 - acc: 0.5043 - val_loss: 1.6829 - val_acc: 0.4477\n",
      "\n",
      "Epoch 00566: val_acc did not improve\n",
      "Epoch 567/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.4925 - acc: 0.5006 - val_loss: 1.6842 - val_acc: 0.4466\n",
      "\n",
      "Epoch 00567: val_acc did not improve\n",
      "Epoch 568/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.4914 - acc: 0.5043 - val_loss: 1.6843 - val_acc: 0.4457\n",
      "\n",
      "Epoch 00568: val_acc did not improve\n",
      "Epoch 569/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4920 - acc: 0.5062 - val_loss: 1.6818 - val_acc: 0.4492\n",
      "\n",
      "Epoch 00569: val_acc did not improve\n",
      "Epoch 570/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4876 - acc: 0.5064 - val_loss: 1.6810 - val_acc: 0.4484\n",
      "\n",
      "Epoch 00570: val_acc did not improve\n",
      "Epoch 571/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4899 - acc: 0.5083 - val_loss: 1.6815 - val_acc: 0.4459\n",
      "\n",
      "Epoch 00571: val_acc did not improve\n",
      "Epoch 572/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4908 - acc: 0.5067 - val_loss: 1.6835 - val_acc: 0.4468\n",
      "\n",
      "Epoch 00572: val_acc did not improve\n",
      "Epoch 573/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4824 - acc: 0.5068 - val_loss: 1.6799 - val_acc: 0.4482\n",
      "\n",
      "Epoch 00573: val_acc did not improve\n",
      "Epoch 574/1000\n",
      "32488/32488 [==============================] - 20s 627us/step - loss: 1.4837 - acc: 0.5067 - val_loss: 1.6795 - val_acc: 0.4478\n",
      "\n",
      "Epoch 00574: val_acc did not improve\n",
      "Epoch 575/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.4828 - acc: 0.5083 - val_loss: 1.6794 - val_acc: 0.4471\n",
      "\n",
      "Epoch 00575: val_acc did not improve\n",
      "Epoch 576/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.4798 - acc: 0.5105 - val_loss: 1.6804 - val_acc: 0.4478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00576: val_acc did not improve\n",
      "Epoch 577/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4828 - acc: 0.5042 - val_loss: 1.6806 - val_acc: 0.4466\n",
      "\n",
      "Epoch 00577: val_acc did not improve\n",
      "Epoch 578/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4782 - acc: 0.5089 - val_loss: 1.6778 - val_acc: 0.4475\n",
      "\n",
      "Epoch 00578: val_acc did not improve\n",
      "Epoch 579/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4800 - acc: 0.5089 - val_loss: 1.6781 - val_acc: 0.4485\n",
      "\n",
      "Epoch 00579: val_acc did not improve\n",
      "Epoch 580/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4768 - acc: 0.5119 - val_loss: 1.6767 - val_acc: 0.4485\n",
      "\n",
      "Epoch 00580: val_acc did not improve\n",
      "Epoch 581/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.4742 - acc: 0.5110 - val_loss: 1.6784 - val_acc: 0.4478\n",
      "\n",
      "Epoch 00581: val_acc did not improve\n",
      "Epoch 582/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4782 - acc: 0.5086 - val_loss: 1.6778 - val_acc: 0.4505\n",
      "\n",
      "Epoch 00582: val_acc did not improve\n",
      "Epoch 583/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4757 - acc: 0.5087 - val_loss: 1.6759 - val_acc: 0.4477\n",
      "\n",
      "Epoch 00583: val_acc did not improve\n",
      "Epoch 584/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4766 - acc: 0.5080 - val_loss: 1.6767 - val_acc: 0.4473\n",
      "\n",
      "Epoch 00584: val_acc did not improve\n",
      "Epoch 585/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4708 - acc: 0.5134 - val_loss: 1.6760 - val_acc: 0.4496\n",
      "\n",
      "Epoch 00585: val_acc did not improve\n",
      "Epoch 586/1000\n",
      "32488/32488 [==============================] - 21s 646us/step - loss: 1.4746 - acc: 0.5107 - val_loss: 1.6760 - val_acc: 0.4482\n",
      "\n",
      "Epoch 00586: val_acc did not improve\n",
      "Epoch 587/1000\n",
      "32488/32488 [==============================] - 21s 637us/step - loss: 1.4745 - acc: 0.5108 - val_loss: 1.6732 - val_acc: 0.4494\n",
      "\n",
      "Epoch 00587: val_acc did not improve\n",
      "Epoch 588/1000\n",
      "32488/32488 [==============================] - 21s 636us/step - loss: 1.4696 - acc: 0.5067 - val_loss: 1.6737 - val_acc: 0.4482\n",
      "\n",
      "Epoch 00588: val_acc did not improve\n",
      "Epoch 589/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4672 - acc: 0.5123 - val_loss: 1.6759 - val_acc: 0.4505\n",
      "\n",
      "Epoch 00589: val_acc did not improve\n",
      "Epoch 590/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.4689 - acc: 0.5124 - val_loss: 1.6743 - val_acc: 0.4471\n",
      "\n",
      "Epoch 00590: val_acc did not improve\n",
      "Epoch 591/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4662 - acc: 0.5119 - val_loss: 1.6749 - val_acc: 0.4498\n",
      "\n",
      "Epoch 00591: val_acc did not improve\n",
      "Epoch 592/1000\n",
      "32488/32488 [==============================] - 20s 625us/step - loss: 1.4610 - acc: 0.5152 - val_loss: 1.6734 - val_acc: 0.4520\n",
      "\n",
      "Epoch 00592: val_acc improved from 0.45064 to 0.45204, saving model to models/feature_network.h5\n",
      "Epoch 593/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4623 - acc: 0.5155 - val_loss: 1.6747 - val_acc: 0.4499\n",
      "\n",
      "Epoch 00593: val_acc did not improve\n",
      "Epoch 594/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4656 - acc: 0.5129 - val_loss: 1.6711 - val_acc: 0.4498\n",
      "\n",
      "Epoch 00594: val_acc did not improve\n",
      "Epoch 595/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.4596 - acc: 0.5152 - val_loss: 1.6750 - val_acc: 0.4489\n",
      "\n",
      "Epoch 00595: val_acc did not improve\n",
      "Epoch 596/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4547 - acc: 0.5159 - val_loss: 1.6714 - val_acc: 0.4480\n",
      "\n",
      "Epoch 00596: val_acc did not improve\n",
      "Epoch 597/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4571 - acc: 0.5145 - val_loss: 1.6702 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00597: val_acc did not improve\n",
      "Epoch 598/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.4573 - acc: 0.5178 - val_loss: 1.6708 - val_acc: 0.4506\n",
      "\n",
      "Epoch 00598: val_acc did not improve\n",
      "Epoch 599/1000\n",
      "32488/32488 [==============================] - 20s 627us/step - loss: 1.4520 - acc: 0.5166 - val_loss: 1.6753 - val_acc: 0.4555\n",
      "\n",
      "Epoch 00599: val_acc improved from 0.45204 to 0.45553, saving model to models/feature_network.h5\n",
      "Epoch 600/1000\n",
      "32488/32488 [==============================] - 20s 629us/step - loss: 1.4558 - acc: 0.5189 - val_loss: 1.6694 - val_acc: 0.4506\n",
      "\n",
      "Epoch 00600: val_acc did not improve\n",
      "Epoch 601/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4536 - acc: 0.5185 - val_loss: 1.6718 - val_acc: 0.4508\n",
      "\n",
      "Epoch 00601: val_acc did not improve\n",
      "Epoch 602/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4531 - acc: 0.5164 - val_loss: 1.6711 - val_acc: 0.4548\n",
      "\n",
      "Epoch 00602: val_acc did not improve\n",
      "Epoch 603/1000\n",
      "32488/32488 [==============================] - 21s 636us/step - loss: 1.4524 - acc: 0.5174 - val_loss: 1.6674 - val_acc: 0.4533\n",
      "\n",
      "Epoch 00603: val_acc did not improve\n",
      "Epoch 604/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.4501 - acc: 0.5176 - val_loss: 1.6699 - val_acc: 0.4487\n",
      "\n",
      "Epoch 00604: val_acc did not improve\n",
      "Epoch 605/1000\n",
      "32488/32488 [==============================] - 21s 638us/step - loss: 1.4471 - acc: 0.5203 - val_loss: 1.6686 - val_acc: 0.4508\n",
      "\n",
      "Epoch 00605: val_acc did not improve\n",
      "Epoch 606/1000\n",
      "32488/32488 [==============================] - 21s 634us/step - loss: 1.4463 - acc: 0.5176 - val_loss: 1.6678 - val_acc: 0.4496\n",
      "\n",
      "Epoch 00606: val_acc did not improve\n",
      "Epoch 607/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4479 - acc: 0.5202 - val_loss: 1.6673 - val_acc: 0.4496\n",
      "\n",
      "Epoch 00607: val_acc did not improve\n",
      "Epoch 608/1000\n",
      "32488/32488 [==============================] - 20s 625us/step - loss: 1.4420 - acc: 0.5191 - val_loss: 1.6709 - val_acc: 0.4506\n",
      "\n",
      "Epoch 00608: val_acc did not improve\n",
      "Epoch 609/1000\n",
      "32488/32488 [==============================] - 20s 630us/step - loss: 1.4449 - acc: 0.5237 - val_loss: 1.6674 - val_acc: 0.4538\n",
      "\n",
      "Epoch 00609: val_acc did not improve\n",
      "Epoch 610/1000\n",
      "32488/32488 [==============================] - 21s 631us/step - loss: 1.4381 - acc: 0.5225 - val_loss: 1.6675 - val_acc: 0.4547\n",
      "\n",
      "Epoch 00610: val_acc did not improve\n",
      "Epoch 611/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4392 - acc: 0.5218 - val_loss: 1.6668 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00611: val_acc did not improve\n",
      "Epoch 612/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4376 - acc: 0.5231 - val_loss: 1.6655 - val_acc: 0.4536\n",
      "\n",
      "Epoch 00612: val_acc did not improve\n",
      "Epoch 613/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4370 - acc: 0.5203 - val_loss: 1.6714 - val_acc: 0.4517\n",
      "\n",
      "Epoch 00613: val_acc did not improve\n",
      "Epoch 614/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4365 - acc: 0.5204 - val_loss: 1.6658 - val_acc: 0.4545\n",
      "\n",
      "Epoch 00614: val_acc did not improve\n",
      "Epoch 615/1000\n",
      "32488/32488 [==============================] - 20s 625us/step - loss: 1.4342 - acc: 0.5216 - val_loss: 1.6641 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00615: val_acc did not improve\n",
      "Epoch 616/1000\n",
      "32488/32488 [==============================] - 21s 635us/step - loss: 1.4310 - acc: 0.5211 - val_loss: 1.6671 - val_acc: 0.4534\n",
      "\n",
      "Epoch 00616: val_acc did not improve\n",
      "Epoch 617/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.4317 - acc: 0.5234 - val_loss: 1.6635 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00617: val_acc did not improve\n",
      "Epoch 618/1000\n",
      "32488/32488 [==============================] - 20s 628us/step - loss: 1.4352 - acc: 0.5225 - val_loss: 1.6638 - val_acc: 0.4520\n",
      "\n",
      "Epoch 00618: val_acc did not improve\n",
      "Epoch 619/1000\n",
      "32488/32488 [==============================] - 20s 629us/step - loss: 1.4264 - acc: 0.5254 - val_loss: 1.6680 - val_acc: 0.4538\n",
      "\n",
      "Epoch 00619: val_acc did not improve\n",
      "Epoch 620/1000\n",
      "32488/32488 [==============================] - 20s 630us/step - loss: 1.4292 - acc: 0.5237 - val_loss: 1.6672 - val_acc: 0.4564\n",
      "\n",
      "Epoch 00620: val_acc improved from 0.45553 to 0.45640, saving model to models/feature_network.h5\n",
      "Epoch 621/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.4240 - acc: 0.5263 - val_loss: 1.6646 - val_acc: 0.4538\n",
      "\n",
      "Epoch 00621: val_acc did not improve\n",
      "Epoch 622/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4265 - acc: 0.5250 - val_loss: 1.6643 - val_acc: 0.4503\n",
      "\n",
      "Epoch 00622: val_acc did not improve\n",
      "Epoch 623/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.4226 - acc: 0.5282 - val_loss: 1.6626 - val_acc: 0.4534\n",
      "\n",
      "Epoch 00623: val_acc did not improve\n",
      "Epoch 624/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.4244 - acc: 0.5254 - val_loss: 1.6621 - val_acc: 0.4534\n",
      "\n",
      "Epoch 00624: val_acc did not improve\n",
      "Epoch 625/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4259 - acc: 0.5247 - val_loss: 1.6624 - val_acc: 0.4520\n",
      "\n",
      "Epoch 00625: val_acc did not improve\n",
      "Epoch 626/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4244 - acc: 0.5253 - val_loss: 1.6623 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00626: val_acc did not improve\n",
      "Epoch 627/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4207 - acc: 0.5276 - val_loss: 1.6605 - val_acc: 0.4569\n",
      "\n",
      "Epoch 00627: val_acc improved from 0.45640 to 0.45693, saving model to models/feature_network.h5\n",
      "Epoch 628/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4249 - acc: 0.5257 - val_loss: 1.6628 - val_acc: 0.4573\n",
      "\n",
      "Epoch 00628: val_acc improved from 0.45693 to 0.45728, saving model to models/feature_network.h5\n",
      "Epoch 629/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4202 - acc: 0.5275 - val_loss: 1.6620 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00629: val_acc did not improve\n",
      "Epoch 630/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4190 - acc: 0.5286 - val_loss: 1.6619 - val_acc: 0.4543\n",
      "\n",
      "Epoch 00630: val_acc did not improve\n",
      "Epoch 631/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4137 - acc: 0.5275 - val_loss: 1.6628 - val_acc: 0.4555\n",
      "\n",
      "Epoch 00631: val_acc did not improve\n",
      "Epoch 632/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.4152 - acc: 0.5266 - val_loss: 1.6586 - val_acc: 0.4583\n",
      "\n",
      "Epoch 00632: val_acc improved from 0.45728 to 0.45833, saving model to models/feature_network.h5\n",
      "Epoch 633/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.4132 - acc: 0.5304 - val_loss: 1.6616 - val_acc: 0.4533\n",
      "\n",
      "Epoch 00633: val_acc did not improve\n",
      "Epoch 634/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.4148 - acc: 0.5265 - val_loss: 1.6623 - val_acc: 0.4564\n",
      "\n",
      "Epoch 00634: val_acc did not improve\n",
      "Epoch 635/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.4108 - acc: 0.5313 - val_loss: 1.6588 - val_acc: 0.4594\n",
      "\n",
      "Epoch 00635: val_acc improved from 0.45833 to 0.45937, saving model to models/feature_network.h5\n",
      "Epoch 636/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4117 - acc: 0.5296 - val_loss: 1.6599 - val_acc: 0.4548\n",
      "\n",
      "Epoch 00636: val_acc did not improve\n",
      "Epoch 637/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.4076 - acc: 0.5304 - val_loss: 1.6585 - val_acc: 0.4557\n",
      "\n",
      "Epoch 00637: val_acc did not improve\n",
      "Epoch 638/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.4092 - acc: 0.5306 - val_loss: 1.6580 - val_acc: 0.4548\n",
      "\n",
      "Epoch 00638: val_acc did not improve\n",
      "Epoch 639/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.4054 - acc: 0.5340 - val_loss: 1.6584 - val_acc: 0.4573\n",
      "\n",
      "Epoch 00639: val_acc did not improve\n",
      "Epoch 640/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4031 - acc: 0.5320 - val_loss: 1.6578 - val_acc: 0.4569\n",
      "\n",
      "Epoch 00640: val_acc did not improve\n",
      "Epoch 641/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.4061 - acc: 0.5315 - val_loss: 1.6565 - val_acc: 0.4562\n",
      "\n",
      "Epoch 00641: val_acc did not improve\n",
      "Epoch 642/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.4035 - acc: 0.5348 - val_loss: 1.6590 - val_acc: 0.4578\n",
      "\n",
      "Epoch 00642: val_acc did not improve\n",
      "Epoch 643/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.4043 - acc: 0.5336 - val_loss: 1.6560 - val_acc: 0.4564\n",
      "\n",
      "Epoch 00643: val_acc did not improve\n",
      "Epoch 644/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.3988 - acc: 0.5380 - val_loss: 1.6562 - val_acc: 0.4589\n",
      "\n",
      "Epoch 00644: val_acc did not improve\n",
      "Epoch 645/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.4007 - acc: 0.5315 - val_loss: 1.6562 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00645: val_acc did not improve\n",
      "Epoch 646/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3967 - acc: 0.5332 - val_loss: 1.6560 - val_acc: 0.4569\n",
      "\n",
      "Epoch 00646: val_acc did not improve\n",
      "Epoch 647/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3947 - acc: 0.5363 - val_loss: 1.6553 - val_acc: 0.4609\n",
      "\n",
      "Epoch 00647: val_acc improved from 0.45937 to 0.46095, saving model to models/feature_network.h5\n",
      "Epoch 648/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3973 - acc: 0.5348 - val_loss: 1.6552 - val_acc: 0.4597\n",
      "\n",
      "Epoch 00648: val_acc did not improve\n",
      "Epoch 649/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3972 - acc: 0.5337 - val_loss: 1.6623 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00649: val_acc did not improve\n",
      "Epoch 650/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.3961 - acc: 0.5359 - val_loss: 1.6527 - val_acc: 0.4592\n",
      "\n",
      "Epoch 00650: val_acc did not improve\n",
      "Epoch 651/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3930 - acc: 0.5352 - val_loss: 1.6571 - val_acc: 0.4575\n",
      "\n",
      "Epoch 00651: val_acc did not improve\n",
      "Epoch 652/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3950 - acc: 0.5360 - val_loss: 1.6531 - val_acc: 0.4582\n",
      "\n",
      "Epoch 00652: val_acc did not improve\n",
      "Epoch 653/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3903 - acc: 0.5367 - val_loss: 1.6534 - val_acc: 0.4583\n",
      "\n",
      "Epoch 00653: val_acc did not improve\n",
      "Epoch 654/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.3941 - acc: 0.5343 - val_loss: 1.6510 - val_acc: 0.4606\n",
      "\n",
      "Epoch 00654: val_acc did not improve\n",
      "Epoch 655/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3854 - acc: 0.5371 - val_loss: 1.6537 - val_acc: 0.4568\n",
      "\n",
      "Epoch 00655: val_acc did not improve\n",
      "Epoch 656/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3881 - acc: 0.5365 - val_loss: 1.6517 - val_acc: 0.4599\n",
      "\n",
      "Epoch 00656: val_acc did not improve\n",
      "Epoch 657/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.3838 - acc: 0.5369 - val_loss: 1.6536 - val_acc: 0.4606\n",
      "\n",
      "Epoch 00657: val_acc did not improve\n",
      "Epoch 658/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.3861 - acc: 0.5368 - val_loss: 1.6535 - val_acc: 0.4602\n",
      "\n",
      "Epoch 00658: val_acc did not improve\n",
      "Epoch 659/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.3823 - acc: 0.5412 - val_loss: 1.6524 - val_acc: 0.4587\n",
      "\n",
      "Epoch 00659: val_acc did not improve\n",
      "Epoch 660/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3863 - acc: 0.5391 - val_loss: 1.6514 - val_acc: 0.4594\n",
      "\n",
      "Epoch 00660: val_acc did not improve\n",
      "Epoch 661/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3807 - acc: 0.5395 - val_loss: 1.6515 - val_acc: 0.4587\n",
      "\n",
      "Epoch 00661: val_acc did not improve\n",
      "Epoch 662/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3805 - acc: 0.5409 - val_loss: 1.6502 - val_acc: 0.4595\n",
      "\n",
      "Epoch 00662: val_acc did not improve\n",
      "Epoch 663/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.3825 - acc: 0.5383 - val_loss: 1.6531 - val_acc: 0.4580\n",
      "\n",
      "Epoch 00663: val_acc did not improve\n",
      "Epoch 664/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3795 - acc: 0.5400 - val_loss: 1.6513 - val_acc: 0.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00664: val_acc improved from 0.46095 to 0.46112, saving model to models/feature_network.h5\n",
      "Epoch 665/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.3749 - acc: 0.5427 - val_loss: 1.6507 - val_acc: 0.4592\n",
      "\n",
      "Epoch 00665: val_acc did not improve\n",
      "Epoch 666/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.3715 - acc: 0.5404 - val_loss: 1.6550 - val_acc: 0.4578\n",
      "\n",
      "Epoch 00666: val_acc did not improve\n",
      "Epoch 667/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3702 - acc: 0.5413 - val_loss: 1.6500 - val_acc: 0.4616\n",
      "\n",
      "Epoch 00667: val_acc improved from 0.46112 to 0.46165, saving model to models/feature_network.h5\n",
      "Epoch 668/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.3701 - acc: 0.5442 - val_loss: 1.6498 - val_acc: 0.4608\n",
      "\n",
      "Epoch 00668: val_acc did not improve\n",
      "Epoch 669/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.3693 - acc: 0.5448 - val_loss: 1.6510 - val_acc: 0.4630\n",
      "\n",
      "Epoch 00669: val_acc improved from 0.46165 to 0.46304, saving model to models/feature_network.h5\n",
      "Epoch 670/1000\n",
      "32488/32488 [==============================] - 20s 627us/step - loss: 1.3668 - acc: 0.5472 - val_loss: 1.6484 - val_acc: 0.4609\n",
      "\n",
      "Epoch 00670: val_acc did not improve\n",
      "Epoch 671/1000\n",
      "32488/32488 [==============================] - 20s 631us/step - loss: 1.3628 - acc: 0.5454 - val_loss: 1.6474 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00671: val_acc improved from 0.46304 to 0.46479, saving model to models/feature_network.h5\n",
      "Epoch 672/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3666 - acc: 0.5440 - val_loss: 1.6520 - val_acc: 0.4597\n",
      "\n",
      "Epoch 00672: val_acc did not improve\n",
      "Epoch 673/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.3655 - acc: 0.5441 - val_loss: 1.6478 - val_acc: 0.4632\n",
      "\n",
      "Epoch 00673: val_acc did not improve\n",
      "Epoch 674/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.3671 - acc: 0.5411 - val_loss: 1.6465 - val_acc: 0.4637\n",
      "\n",
      "Epoch 00674: val_acc did not improve\n",
      "Epoch 675/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3699 - acc: 0.5450 - val_loss: 1.6468 - val_acc: 0.4597\n",
      "\n",
      "Epoch 00675: val_acc did not improve\n",
      "Epoch 676/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.3581 - acc: 0.5493 - val_loss: 1.6480 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00676: val_acc did not improve\n",
      "Epoch 677/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.3578 - acc: 0.5469 - val_loss: 1.6460 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00677: val_acc improved from 0.46479 to 0.46497, saving model to models/feature_network.h5\n",
      "Epoch 678/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3571 - acc: 0.5483 - val_loss: 1.6466 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00678: val_acc did not improve\n",
      "Epoch 679/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.3558 - acc: 0.5490 - val_loss: 1.6475 - val_acc: 0.4599\n",
      "\n",
      "Epoch 00679: val_acc did not improve\n",
      "Epoch 680/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.3616 - acc: 0.5435 - val_loss: 1.6454 - val_acc: 0.4609\n",
      "\n",
      "Epoch 00680: val_acc did not improve\n",
      "Epoch 681/1000\n",
      "32488/32488 [==============================] - 20s 625us/step - loss: 1.3585 - acc: 0.5487 - val_loss: 1.6443 - val_acc: 0.4641\n",
      "\n",
      "Epoch 00681: val_acc did not improve\n",
      "Epoch 682/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3650 - acc: 0.5416 - val_loss: 1.6510 - val_acc: 0.4602\n",
      "\n",
      "Epoch 00682: val_acc did not improve\n",
      "Epoch 683/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.3578 - acc: 0.5436 - val_loss: 1.6468 - val_acc: 0.4620\n",
      "\n",
      "Epoch 00683: val_acc did not improve\n",
      "Epoch 684/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3494 - acc: 0.5518 - val_loss: 1.6455 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00684: val_acc did not improve\n",
      "Epoch 685/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3468 - acc: 0.5503 - val_loss: 1.6444 - val_acc: 0.4627\n",
      "\n",
      "Epoch 00685: val_acc did not improve\n",
      "Epoch 686/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3523 - acc: 0.5482 - val_loss: 1.6456 - val_acc: 0.4599\n",
      "\n",
      "Epoch 00686: val_acc did not improve\n",
      "Epoch 687/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.3508 - acc: 0.5500 - val_loss: 1.6460 - val_acc: 0.4641\n",
      "\n",
      "Epoch 00687: val_acc did not improve\n",
      "Epoch 688/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.3475 - acc: 0.5549 - val_loss: 1.6423 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00688: val_acc did not improve\n",
      "Epoch 689/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3485 - acc: 0.5522 - val_loss: 1.6447 - val_acc: 0.4606\n",
      "\n",
      "Epoch 00689: val_acc did not improve\n",
      "Epoch 690/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3498 - acc: 0.5497 - val_loss: 1.6447 - val_acc: 0.4662\n",
      "\n",
      "Epoch 00690: val_acc improved from 0.46497 to 0.46619, saving model to models/feature_network.h5\n",
      "Epoch 691/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3473 - acc: 0.5502 - val_loss: 1.6447 - val_acc: 0.4618\n",
      "\n",
      "Epoch 00691: val_acc did not improve\n",
      "Epoch 692/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3383 - acc: 0.5524 - val_loss: 1.6419 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00692: val_acc did not improve\n",
      "Epoch 693/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.3470 - acc: 0.5510 - val_loss: 1.6432 - val_acc: 0.4625\n",
      "\n",
      "Epoch 00693: val_acc did not improve\n",
      "Epoch 694/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3424 - acc: 0.5517 - val_loss: 1.6410 - val_acc: 0.4672\n",
      "\n",
      "Epoch 00694: val_acc improved from 0.46619 to 0.46724, saving model to models/feature_network.h5\n",
      "Epoch 695/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3398 - acc: 0.5524 - val_loss: 1.6444 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00695: val_acc did not improve\n",
      "Epoch 696/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3431 - acc: 0.5513 - val_loss: 1.6414 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00696: val_acc did not improve\n",
      "Epoch 697/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3382 - acc: 0.5522 - val_loss: 1.6423 - val_acc: 0.4629\n",
      "\n",
      "Epoch 00697: val_acc did not improve\n",
      "Epoch 698/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.3334 - acc: 0.5539 - val_loss: 1.6430 - val_acc: 0.4634\n",
      "\n",
      "Epoch 00698: val_acc did not improve\n",
      "Epoch 699/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3383 - acc: 0.5542 - val_loss: 1.6411 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00699: val_acc improved from 0.46724 to 0.46759, saving model to models/feature_network.h5\n",
      "Epoch 700/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3321 - acc: 0.5573 - val_loss: 1.6445 - val_acc: 0.4662\n",
      "\n",
      "Epoch 00700: val_acc did not improve\n",
      "Epoch 701/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3362 - acc: 0.5534 - val_loss: 1.6421 - val_acc: 0.4606\n",
      "\n",
      "Epoch 00701: val_acc did not improve\n",
      "Epoch 702/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3348 - acc: 0.5549 - val_loss: 1.6415 - val_acc: 0.4634\n",
      "\n",
      "Epoch 00702: val_acc did not improve\n",
      "Epoch 703/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3270 - acc: 0.5536 - val_loss: 1.6443 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00703: val_acc did not improve\n",
      "Epoch 704/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3286 - acc: 0.5554 - val_loss: 1.6393 - val_acc: 0.4639\n",
      "\n",
      "Epoch 00704: val_acc did not improve\n",
      "Epoch 705/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.3344 - acc: 0.5525 - val_loss: 1.6405 - val_acc: 0.4620\n",
      "\n",
      "Epoch 00705: val_acc did not improve\n",
      "Epoch 706/1000\n",
      "32488/32488 [==============================] - 20s 624us/step - loss: 1.3256 - acc: 0.5573 - val_loss: 1.6389 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00706: val_acc did not improve\n",
      "Epoch 707/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.3270 - acc: 0.5551 - val_loss: 1.6381 - val_acc: 0.4678\n",
      "\n",
      "Epoch 00707: val_acc improved from 0.46759 to 0.46776, saving model to models/feature_network.h5\n",
      "Epoch 708/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.3258 - acc: 0.5573 - val_loss: 1.6416 - val_acc: 0.4630\n",
      "\n",
      "Epoch 00708: val_acc did not improve\n",
      "Epoch 709/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3260 - acc: 0.5565 - val_loss: 1.6412 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00709: val_acc did not improve\n",
      "Epoch 710/1000\n",
      "32488/32488 [==============================] - 20s 628us/step - loss: 1.3228 - acc: 0.5587 - val_loss: 1.6470 - val_acc: 0.4644\n",
      "\n",
      "Epoch 00710: val_acc did not improve\n",
      "Epoch 711/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.3225 - acc: 0.5595 - val_loss: 1.6401 - val_acc: 0.4665\n",
      "\n",
      "Epoch 00711: val_acc did not improve\n",
      "Epoch 712/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.3166 - acc: 0.5602 - val_loss: 1.6377 - val_acc: 0.4644\n",
      "\n",
      "Epoch 00712: val_acc did not improve\n",
      "Epoch 713/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.3132 - acc: 0.5641 - val_loss: 1.6386 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00713: val_acc did not improve\n",
      "Epoch 714/1000\n",
      "32488/32488 [==============================] - 20s 630us/step - loss: 1.3129 - acc: 0.5613 - val_loss: 1.6380 - val_acc: 0.4630\n",
      "\n",
      "Epoch 00714: val_acc did not improve\n",
      "Epoch 715/1000\n",
      "32488/32488 [==============================] - 21s 631us/step - loss: 1.3250 - acc: 0.5551 - val_loss: 1.6376 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00715: val_acc did not improve\n",
      "Epoch 716/1000\n",
      "32488/32488 [==============================] - 21s 638us/step - loss: 1.3135 - acc: 0.5619 - val_loss: 1.6409 - val_acc: 0.4658\n",
      "\n",
      "Epoch 00716: val_acc did not improve\n",
      "Epoch 717/1000\n",
      "32488/32488 [==============================] - 20s 629us/step - loss: 1.3148 - acc: 0.5611 - val_loss: 1.6406 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00717: val_acc did not improve\n",
      "Epoch 718/1000\n",
      "32488/32488 [==============================] - 20s 631us/step - loss: 1.3107 - acc: 0.5602 - val_loss: 1.6355 - val_acc: 0.4658\n",
      "\n",
      "Epoch 00718: val_acc did not improve\n",
      "Epoch 719/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.3185 - acc: 0.5593 - val_loss: 1.6366 - val_acc: 0.4669\n",
      "\n",
      "Epoch 00719: val_acc did not improve\n",
      "Epoch 720/1000\n",
      "32488/32488 [==============================] - 21s 639us/step - loss: 1.3108 - acc: 0.5605 - val_loss: 1.6404 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00720: val_acc did not improve\n",
      "Epoch 721/1000\n",
      "32488/32488 [==============================] - 20s 631us/step - loss: 1.3088 - acc: 0.5629 - val_loss: 1.6365 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00721: val_acc did not improve\n",
      "Epoch 722/1000\n",
      "32488/32488 [==============================] - 21s 635us/step - loss: 1.3123 - acc: 0.5611 - val_loss: 1.6375 - val_acc: 0.4639\n",
      "\n",
      "Epoch 00722: val_acc did not improve\n",
      "Epoch 723/1000\n",
      "32488/32488 [==============================] - 21s 632us/step - loss: 1.3089 - acc: 0.5629 - val_loss: 1.6373 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00723: val_acc did not improve\n",
      "Epoch 724/1000\n",
      "32488/32488 [==============================] - 20s 626us/step - loss: 1.3137 - acc: 0.5619 - val_loss: 1.6389 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00724: val_acc did not improve\n",
      "Epoch 725/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.3043 - acc: 0.5642 - val_loss: 1.6360 - val_acc: 0.4664\n",
      "\n",
      "Epoch 00725: val_acc did not improve\n",
      "Epoch 726/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3079 - acc: 0.5624 - val_loss: 1.6358 - val_acc: 0.4651\n",
      "\n",
      "Epoch 00726: val_acc did not improve\n",
      "Epoch 727/1000\n",
      "32488/32488 [==============================] - 20s 628us/step - loss: 1.3055 - acc: 0.5642 - val_loss: 1.6358 - val_acc: 0.4637\n",
      "\n",
      "Epoch 00727: val_acc did not improve\n",
      "Epoch 728/1000\n",
      "32488/32488 [==============================] - 20s 631us/step - loss: 1.2972 - acc: 0.5666 - val_loss: 1.6375 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00728: val_acc improved from 0.46776 to 0.47003, saving model to models/feature_network.h5\n",
      "Epoch 729/1000\n",
      "32488/32488 [==============================] - 20s 627us/step - loss: 1.2996 - acc: 0.5677 - val_loss: 1.6377 - val_acc: 0.4697\n",
      "\n",
      "Epoch 00729: val_acc did not improve\n",
      "Epoch 730/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.3049 - acc: 0.5662 - val_loss: 1.6348 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00730: val_acc did not improve\n",
      "Epoch 731/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.3019 - acc: 0.5666 - val_loss: 1.6341 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00731: val_acc did not improve\n",
      "Epoch 732/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2995 - acc: 0.5669 - val_loss: 1.6342 - val_acc: 0.4646\n",
      "\n",
      "Epoch 00732: val_acc did not improve\n",
      "Epoch 733/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2974 - acc: 0.5677 - val_loss: 1.6333 - val_acc: 0.4669\n",
      "\n",
      "Epoch 00733: val_acc did not improve\n",
      "Epoch 734/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2926 - acc: 0.5672 - val_loss: 1.6353 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00734: val_acc did not improve\n",
      "Epoch 735/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2953 - acc: 0.5668 - val_loss: 1.6370 - val_acc: 0.4662\n",
      "\n",
      "Epoch 00735: val_acc did not improve\n",
      "Epoch 736/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2928 - acc: 0.5666 - val_loss: 1.6348 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00736: val_acc did not improve\n",
      "Epoch 737/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2931 - acc: 0.5697 - val_loss: 1.6390 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00737: val_acc did not improve\n",
      "Epoch 738/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2910 - acc: 0.5674 - val_loss: 1.6377 - val_acc: 0.4664\n",
      "\n",
      "Epoch 00738: val_acc did not improve\n",
      "Epoch 739/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2878 - acc: 0.5685 - val_loss: 1.6314 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00739: val_acc did not improve\n",
      "Epoch 740/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2855 - acc: 0.5701 - val_loss: 1.6341 - val_acc: 0.4672\n",
      "\n",
      "Epoch 00740: val_acc did not improve\n",
      "Epoch 741/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2924 - acc: 0.5692 - val_loss: 1.6358 - val_acc: 0.4636\n",
      "\n",
      "Epoch 00741: val_acc did not improve\n",
      "Epoch 742/1000\n",
      "32488/32488 [==============================] - 20s 628us/step - loss: 1.2836 - acc: 0.5725 - val_loss: 1.6344 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00742: val_acc did not improve\n",
      "Epoch 743/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2859 - acc: 0.5700 - val_loss: 1.6345 - val_acc: 0.4699\n",
      "\n",
      "Epoch 00743: val_acc did not improve\n",
      "Epoch 744/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2808 - acc: 0.5732 - val_loss: 1.6358 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00744: val_acc did not improve\n",
      "Epoch 745/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.2771 - acc: 0.5737 - val_loss: 1.6339 - val_acc: 0.4657\n",
      "\n",
      "Epoch 00745: val_acc did not improve\n",
      "Epoch 746/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2819 - acc: 0.5739 - val_loss: 1.6324 - val_acc: 0.4662\n",
      "\n",
      "Epoch 00746: val_acc did not improve\n",
      "Epoch 747/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2811 - acc: 0.5722 - val_loss: 1.6307 - val_acc: 0.4723\n",
      "\n",
      "Epoch 00747: val_acc improved from 0.47003 to 0.47230, saving model to models/feature_network.h5\n",
      "Epoch 748/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2777 - acc: 0.5764 - val_loss: 1.6340 - val_acc: 0.4639\n",
      "\n",
      "Epoch 00748: val_acc did not improve\n",
      "Epoch 749/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.2790 - acc: 0.5748 - val_loss: 1.6331 - val_acc: 0.4679\n",
      "\n",
      "Epoch 00749: val_acc did not improve\n",
      "Epoch 750/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2755 - acc: 0.5740 - val_loss: 1.6312 - val_acc: 0.4678\n",
      "\n",
      "Epoch 00750: val_acc did not improve\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2755 - acc: 0.5742 - val_loss: 1.6313 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00751: val_acc did not improve\n",
      "Epoch 752/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.2769 - acc: 0.5729 - val_loss: 1.6354 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00752: val_acc did not improve\n",
      "Epoch 753/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2767 - acc: 0.5739 - val_loss: 1.6346 - val_acc: 0.4650\n",
      "\n",
      "Epoch 00753: val_acc did not improve\n",
      "Epoch 754/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.2738 - acc: 0.5751 - val_loss: 1.6286 - val_acc: 0.4674\n",
      "\n",
      "Epoch 00754: val_acc did not improve\n",
      "Epoch 755/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2746 - acc: 0.5755 - val_loss: 1.6299 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00755: val_acc did not improve\n",
      "Epoch 756/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2702 - acc: 0.5734 - val_loss: 1.6284 - val_acc: 0.4662\n",
      "\n",
      "Epoch 00756: val_acc did not improve\n",
      "Epoch 757/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.2670 - acc: 0.5789 - val_loss: 1.6290 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00757: val_acc did not improve\n",
      "Epoch 758/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2663 - acc: 0.5785 - val_loss: 1.6324 - val_acc: 0.4634\n",
      "\n",
      "Epoch 00758: val_acc did not improve\n",
      "Epoch 759/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2651 - acc: 0.5724 - val_loss: 1.6292 - val_acc: 0.4702\n",
      "\n",
      "Epoch 00759: val_acc did not improve\n",
      "Epoch 760/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2655 - acc: 0.5753 - val_loss: 1.6305 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00760: val_acc did not improve\n",
      "Epoch 761/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2638 - acc: 0.5787 - val_loss: 1.6327 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00761: val_acc did not improve\n",
      "Epoch 762/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2618 - acc: 0.5788 - val_loss: 1.6309 - val_acc: 0.4674\n",
      "\n",
      "Epoch 00762: val_acc did not improve\n",
      "Epoch 763/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2540 - acc: 0.5818 - val_loss: 1.6292 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00763: val_acc did not improve\n",
      "Epoch 764/1000\n",
      "32488/32488 [==============================] - 20s 624us/step - loss: 1.2598 - acc: 0.5804 - val_loss: 1.6313 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00764: val_acc did not improve\n",
      "Epoch 765/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2578 - acc: 0.5789 - val_loss: 1.6318 - val_acc: 0.4669\n",
      "\n",
      "Epoch 00765: val_acc did not improve\n",
      "Epoch 766/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2580 - acc: 0.5769 - val_loss: 1.6279 - val_acc: 0.4679\n",
      "\n",
      "Epoch 00766: val_acc did not improve\n",
      "Epoch 767/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2603 - acc: 0.5782 - val_loss: 1.6276 - val_acc: 0.4706\n",
      "\n",
      "Epoch 00767: val_acc did not improve\n",
      "Epoch 768/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2587 - acc: 0.5823 - val_loss: 1.6319 - val_acc: 0.4671\n",
      "\n",
      "Epoch 00768: val_acc did not improve\n",
      "Epoch 769/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2541 - acc: 0.5847 - val_loss: 1.6313 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00769: val_acc did not improve\n",
      "Epoch 770/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2545 - acc: 0.5817 - val_loss: 1.6299 - val_acc: 0.4669\n",
      "\n",
      "Epoch 00770: val_acc did not improve\n",
      "Epoch 771/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2541 - acc: 0.5800 - val_loss: 1.6263 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00771: val_acc did not improve\n",
      "Epoch 772/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2568 - acc: 0.5811 - val_loss: 1.6326 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00772: val_acc did not improve\n",
      "Epoch 773/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.2521 - acc: 0.5816 - val_loss: 1.6305 - val_acc: 0.4686\n",
      "\n",
      "Epoch 00773: val_acc did not improve\n",
      "Epoch 774/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.2525 - acc: 0.5812 - val_loss: 1.6260 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00774: val_acc did not improve\n",
      "Epoch 775/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2523 - acc: 0.5814 - val_loss: 1.6273 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00775: val_acc did not improve\n",
      "Epoch 776/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2469 - acc: 0.5844 - val_loss: 1.6267 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00776: val_acc did not improve\n",
      "Epoch 777/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2469 - acc: 0.5846 - val_loss: 1.6269 - val_acc: 0.4686\n",
      "\n",
      "Epoch 00777: val_acc did not improve\n",
      "Epoch 778/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.2478 - acc: 0.5826 - val_loss: 1.6260 - val_acc: 0.4704\n",
      "\n",
      "Epoch 00778: val_acc did not improve\n",
      "Epoch 779/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2440 - acc: 0.5873 - val_loss: 1.6259 - val_acc: 0.4658\n",
      "\n",
      "Epoch 00779: val_acc did not improve\n",
      "Epoch 780/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.2426 - acc: 0.5850 - val_loss: 1.6257 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00780: val_acc did not improve\n",
      "Epoch 781/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2441 - acc: 0.5851 - val_loss: 1.6264 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00781: val_acc did not improve\n",
      "Epoch 782/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2402 - acc: 0.5861 - val_loss: 1.6263 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00782: val_acc did not improve\n",
      "Epoch 783/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2318 - acc: 0.5886 - val_loss: 1.6281 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00783: val_acc did not improve\n",
      "Epoch 784/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.2352 - acc: 0.5871 - val_loss: 1.6271 - val_acc: 0.4686\n",
      "\n",
      "Epoch 00784: val_acc did not improve\n",
      "Epoch 785/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.2370 - acc: 0.5889 - val_loss: 1.6267 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00785: val_acc did not improve\n",
      "Epoch 786/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2347 - acc: 0.5852 - val_loss: 1.6249 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00786: val_acc did not improve\n",
      "Epoch 787/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2291 - acc: 0.5903 - val_loss: 1.6289 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00787: val_acc did not improve\n",
      "Epoch 788/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2350 - acc: 0.5884 - val_loss: 1.6275 - val_acc: 0.4728\n",
      "\n",
      "Epoch 00788: val_acc improved from 0.47230 to 0.47283, saving model to models/feature_network.h5\n",
      "Epoch 789/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2299 - acc: 0.5876 - val_loss: 1.6290 - val_acc: 0.4686\n",
      "\n",
      "Epoch 00789: val_acc did not improve\n",
      "Epoch 790/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2297 - acc: 0.5870 - val_loss: 1.6242 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00790: val_acc did not improve\n",
      "Epoch 791/1000\n",
      "32488/32488 [==============================] - 20s 629us/step - loss: 1.2320 - acc: 0.5884 - val_loss: 1.6278 - val_acc: 0.4669\n",
      "\n",
      "Epoch 00791: val_acc did not improve\n",
      "Epoch 792/1000\n",
      "32488/32488 [==============================] - 21s 636us/step - loss: 1.2271 - acc: 0.5924 - val_loss: 1.6260 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00792: val_acc did not improve\n",
      "Epoch 793/1000\n",
      "32488/32488 [==============================] - 21s 635us/step - loss: 1.2342 - acc: 0.5881 - val_loss: 1.6241 - val_acc: 0.4702\n",
      "\n",
      "Epoch 00793: val_acc did not improve\n",
      "Epoch 794/1000\n",
      "32488/32488 [==============================] - 21s 633us/step - loss: 1.2284 - acc: 0.5939 - val_loss: 1.6276 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00794: val_acc did not improve\n",
      "Epoch 795/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2228 - acc: 0.5929 - val_loss: 1.6250 - val_acc: 0.4723\n",
      "\n",
      "Epoch 00795: val_acc did not improve\n",
      "Epoch 796/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.2305 - acc: 0.5881 - val_loss: 1.6226 - val_acc: 0.4678\n",
      "\n",
      "Epoch 00796: val_acc did not improve\n",
      "Epoch 797/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.2193 - acc: 0.5944 - val_loss: 1.6288 - val_acc: 0.4672\n",
      "\n",
      "Epoch 00797: val_acc did not improve\n",
      "Epoch 798/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2204 - acc: 0.5923 - val_loss: 1.6251 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00798: val_acc did not improve\n",
      "Epoch 799/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2186 - acc: 0.5934 - val_loss: 1.6256 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00799: val_acc did not improve\n",
      "Epoch 800/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2219 - acc: 0.5882 - val_loss: 1.6253 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00800: val_acc did not improve\n",
      "Epoch 801/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2200 - acc: 0.5923 - val_loss: 1.6218 - val_acc: 0.4697\n",
      "\n",
      "Epoch 00801: val_acc did not improve\n",
      "Epoch 802/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.2192 - acc: 0.5941 - val_loss: 1.6255 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00802: val_acc did not improve\n",
      "Epoch 803/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2142 - acc: 0.5927 - val_loss: 1.6257 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00803: val_acc did not improve\n",
      "Epoch 804/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.2159 - acc: 0.5922 - val_loss: 1.6221 - val_acc: 0.4734\n",
      "\n",
      "Epoch 00804: val_acc improved from 0.47283 to 0.47335, saving model to models/feature_network.h5\n",
      "Epoch 805/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2126 - acc: 0.5964 - val_loss: 1.6236 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00805: val_acc did not improve\n",
      "Epoch 806/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2092 - acc: 0.5969 - val_loss: 1.6214 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00806: val_acc did not improve\n",
      "Epoch 807/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.2122 - acc: 0.5952 - val_loss: 1.6218 - val_acc: 0.4704\n",
      "\n",
      "Epoch 00807: val_acc did not improve\n",
      "Epoch 808/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2138 - acc: 0.5933 - val_loss: 1.6222 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00808: val_acc did not improve\n",
      "Epoch 809/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.2044 - acc: 0.5969 - val_loss: 1.6238 - val_acc: 0.4704\n",
      "\n",
      "Epoch 00809: val_acc did not improve\n",
      "Epoch 810/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.2067 - acc: 0.5990 - val_loss: 1.6288 - val_acc: 0.4665\n",
      "\n",
      "Epoch 00810: val_acc did not improve\n",
      "Epoch 811/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2042 - acc: 0.5981 - val_loss: 1.6247 - val_acc: 0.4699\n",
      "\n",
      "Epoch 00811: val_acc did not improve\n",
      "Epoch 812/1000\n",
      "32488/32488 [==============================] - 20s 624us/step - loss: 1.2056 - acc: 0.5970 - val_loss: 1.6215 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00812: val_acc did not improve\n",
      "Epoch 813/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.2080 - acc: 0.5955 - val_loss: 1.6257 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00813: val_acc did not improve\n",
      "Epoch 814/1000\n",
      "32488/32488 [==============================] - 20s 615us/step - loss: 1.2046 - acc: 0.5943 - val_loss: 1.6246 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00814: val_acc did not improve\n",
      "Epoch 815/1000\n",
      "32488/32488 [==============================] - 20s 616us/step - loss: 1.2039 - acc: 0.5972 - val_loss: 1.6251 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00815: val_acc did not improve\n",
      "Epoch 816/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.2025 - acc: 0.5949 - val_loss: 1.6222 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00816: val_acc did not improve\n",
      "Epoch 817/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.2059 - acc: 0.5932 - val_loss: 1.6218 - val_acc: 0.4734\n",
      "\n",
      "Epoch 00817: val_acc improved from 0.47335 to 0.47335, saving model to models/feature_network.h5\n",
      "Epoch 818/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1997 - acc: 0.6014 - val_loss: 1.6199 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00818: val_acc did not improve\n",
      "Epoch 819/1000\n",
      "32488/32488 [==============================] - 20s 623us/step - loss: 1.1999 - acc: 0.6005 - val_loss: 1.6238 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00819: val_acc did not improve\n",
      "Epoch 820/1000\n",
      "32488/32488 [==============================] - 20s 627us/step - loss: 1.1950 - acc: 0.5997 - val_loss: 1.6258 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00820: val_acc did not improve\n",
      "Epoch 821/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.1992 - acc: 0.5972 - val_loss: 1.6236 - val_acc: 0.4686\n",
      "\n",
      "Epoch 00821: val_acc did not improve\n",
      "Epoch 822/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1933 - acc: 0.6020 - val_loss: 1.6236 - val_acc: 0.4721\n",
      "\n",
      "Epoch 00822: val_acc did not improve\n",
      "Epoch 823/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.1975 - acc: 0.5983 - val_loss: 1.6229 - val_acc: 0.4716\n",
      "\n",
      "Epoch 00823: val_acc did not improve\n",
      "Epoch 824/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1936 - acc: 0.6026 - val_loss: 1.6295 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00824: val_acc did not improve\n",
      "Epoch 825/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.1912 - acc: 0.5992 - val_loss: 1.6259 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00825: val_acc did not improve\n",
      "Epoch 826/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1898 - acc: 0.6019 - val_loss: 1.6259 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00826: val_acc did not improve\n",
      "Epoch 827/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1896 - acc: 0.6035 - val_loss: 1.6202 - val_acc: 0.4674\n",
      "\n",
      "Epoch 00827: val_acc did not improve\n",
      "Epoch 828/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.1899 - acc: 0.6009 - val_loss: 1.6230 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00828: val_acc did not improve\n",
      "Epoch 829/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.1847 - acc: 0.6050 - val_loss: 1.6219 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00829: val_acc did not improve\n",
      "Epoch 830/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.1825 - acc: 0.6044 - val_loss: 1.6211 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00830: val_acc did not improve\n",
      "Epoch 831/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1813 - acc: 0.6050 - val_loss: 1.6227 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00831: val_acc did not improve\n",
      "Epoch 832/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1816 - acc: 0.6043 - val_loss: 1.6208 - val_acc: 0.4706\n",
      "\n",
      "Epoch 00832: val_acc did not improve\n",
      "Epoch 833/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1791 - acc: 0.6034 - val_loss: 1.6242 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00833: val_acc did not improve\n",
      "Epoch 834/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.1750 - acc: 0.6088 - val_loss: 1.6233 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00834: val_acc did not improve\n",
      "Epoch 835/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.1844 - acc: 0.6043 - val_loss: 1.6209 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00835: val_acc did not improve\n",
      "Epoch 836/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1774 - acc: 0.6049 - val_loss: 1.6263 - val_acc: 0.4714\n",
      "\n",
      "Epoch 00836: val_acc did not improve\n",
      "Epoch 837/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1766 - acc: 0.6067 - val_loss: 1.6206 - val_acc: 0.4714\n",
      "\n",
      "Epoch 00837: val_acc did not improve\n",
      "Epoch 838/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1749 - acc: 0.6066 - val_loss: 1.6223 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00838: val_acc did not improve\n",
      "Epoch 839/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1773 - acc: 0.6057 - val_loss: 1.6190 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00839: val_acc did not improve\n",
      "Epoch 840/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1770 - acc: 0.6051 - val_loss: 1.6181 - val_acc: 0.4683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00840: val_acc did not improve\n",
      "Epoch 841/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1701 - acc: 0.6077 - val_loss: 1.6209 - val_acc: 0.4678\n",
      "\n",
      "Epoch 00841: val_acc did not improve\n",
      "Epoch 842/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.1735 - acc: 0.6053 - val_loss: 1.6196 - val_acc: 0.4699\n",
      "\n",
      "Epoch 00842: val_acc did not improve\n",
      "Epoch 843/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.1713 - acc: 0.6065 - val_loss: 1.6223 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00843: val_acc did not improve\n",
      "Epoch 844/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.1659 - acc: 0.6086 - val_loss: 1.6179 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00844: val_acc improved from 0.47335 to 0.47388, saving model to models/feature_network.h5\n",
      "Epoch 845/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.1687 - acc: 0.6103 - val_loss: 1.6210 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00845: val_acc did not improve\n",
      "Epoch 846/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.1652 - acc: 0.6087 - val_loss: 1.6190 - val_acc: 0.4699\n",
      "\n",
      "Epoch 00846: val_acc did not improve\n",
      "Epoch 847/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.1571 - acc: 0.6129 - val_loss: 1.6201 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00847: val_acc did not improve\n",
      "Epoch 848/1000\n",
      "32488/32488 [==============================] - 20s 618us/step - loss: 1.1665 - acc: 0.6096 - val_loss: 1.6212 - val_acc: 0.4706\n",
      "\n",
      "Epoch 00848: val_acc did not improve\n",
      "Epoch 849/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1638 - acc: 0.6112 - val_loss: 1.6179 - val_acc: 0.4686\n",
      "\n",
      "Epoch 00849: val_acc did not improve\n",
      "Epoch 850/1000\n",
      "32488/32488 [==============================] - 20s 617us/step - loss: 1.1596 - acc: 0.6111 - val_loss: 1.6202 - val_acc: 0.4737\n",
      "\n",
      "Epoch 00850: val_acc did not improve\n",
      "Epoch 851/1000\n",
      "32488/32488 [==============================] - 20s 619us/step - loss: 1.1630 - acc: 0.6124 - val_loss: 1.6221 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00851: val_acc did not improve\n",
      "Epoch 852/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.1635 - acc: 0.6107 - val_loss: 1.6254 - val_acc: 0.4658\n",
      "\n",
      "Epoch 00852: val_acc did not improve\n",
      "Epoch 853/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.1615 - acc: 0.6133 - val_loss: 1.6190 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00853: val_acc did not improve\n",
      "Epoch 854/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.1605 - acc: 0.6112 - val_loss: 1.6182 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00854: val_acc did not improve\n",
      "Epoch 855/1000\n",
      "32488/32488 [==============================] - 20s 620us/step - loss: 1.1570 - acc: 0.6115 - val_loss: 1.6218 - val_acc: 0.4685\n",
      "\n",
      "Epoch 00855: val_acc did not improve\n",
      "Epoch 856/1000\n",
      "32488/32488 [==============================] - 20s 622us/step - loss: 1.1544 - acc: 0.6144 - val_loss: 1.6196 - val_acc: 0.4711\n",
      "\n",
      "Epoch 00856: val_acc did not improve\n",
      "Epoch 857/1000\n",
      "32488/32488 [==============================] - 20s 621us/step - loss: 1.1511 - acc: 0.6134 - val_loss: 1.6220 - val_acc: 0.4674\n",
      "\n",
      "Epoch 00857: val_acc did not improve\n",
      "Epoch 858/1000\n",
      "32488/32488 [==============================] - 23s 696us/step - loss: 1.1525 - acc: 0.6121 - val_loss: 1.6204 - val_acc: 0.4723\n",
      "\n",
      "Epoch 00858: val_acc did not improve\n",
      "Epoch 859/1000\n",
      "32488/32488 [==============================] - 30s 927us/step - loss: 1.1515 - acc: 0.6155 - val_loss: 1.6174 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00859: val_acc did not improve\n",
      "Epoch 860/1000\n",
      "32488/32488 [==============================] - 29s 905us/step - loss: 1.1547 - acc: 0.6156 - val_loss: 1.6185 - val_acc: 0.4723\n",
      "\n",
      "Epoch 00860: val_acc did not improve\n",
      "Epoch 861/1000\n",
      "32488/32488 [==============================] - 30s 914us/step - loss: 1.1512 - acc: 0.6144 - val_loss: 1.6226 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00861: val_acc did not improve\n",
      "Epoch 862/1000\n",
      "32488/32488 [==============================] - 30s 925us/step - loss: 1.1532 - acc: 0.6105 - val_loss: 1.6248 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00862: val_acc did not improve\n",
      "Epoch 863/1000\n",
      "32488/32488 [==============================] - 30s 928us/step - loss: 1.1523 - acc: 0.6147 - val_loss: 1.6184 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00863: val_acc did not improve\n",
      "Epoch 864/1000\n",
      "32488/32488 [==============================] - 30s 926us/step - loss: 1.1498 - acc: 0.6186 - val_loss: 1.6173 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00864: val_acc did not improve\n",
      "Epoch 865/1000\n",
      "32488/32488 [==============================] - 30s 919us/step - loss: 1.1411 - acc: 0.6147 - val_loss: 1.6185 - val_acc: 0.4697\n",
      "\n",
      "Epoch 00865: val_acc did not improve\n",
      "Epoch 866/1000\n",
      "32488/32488 [==============================] - 30s 929us/step - loss: 1.1435 - acc: 0.6178 - val_loss: 1.6176 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00866: val_acc did not improve\n",
      "Epoch 867/1000\n",
      "32488/32488 [==============================] - 30s 927us/step - loss: 1.1438 - acc: 0.6154 - val_loss: 1.6201 - val_acc: 0.4718\n",
      "\n",
      "Epoch 00867: val_acc did not improve\n",
      "Epoch 868/1000\n",
      "32488/32488 [==============================] - 30s 929us/step - loss: 1.1466 - acc: 0.6172 - val_loss: 1.6152 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00868: val_acc did not improve\n",
      "Epoch 869/1000\n",
      "32488/32488 [==============================] - 31s 944us/step - loss: 1.1392 - acc: 0.6196 - val_loss: 1.6211 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00869: val_acc did not improve\n",
      "Epoch 870/1000\n",
      "32488/32488 [==============================] - 30s 931us/step - loss: 1.1450 - acc: 0.6211 - val_loss: 1.6192 - val_acc: 0.4711\n",
      "\n",
      "Epoch 00870: val_acc did not improve\n",
      "Epoch 871/1000\n",
      "32488/32488 [==============================] - 30s 936us/step - loss: 1.1483 - acc: 0.6146 - val_loss: 1.6167 - val_acc: 0.4718\n",
      "\n",
      "Epoch 00871: val_acc did not improve\n",
      "Epoch 872/1000\n",
      "32488/32488 [==============================] - 31s 940us/step - loss: 1.1357 - acc: 0.6225 - val_loss: 1.6196 - val_acc: 0.4723\n",
      "\n",
      "Epoch 00872: val_acc did not improve\n",
      "Epoch 873/1000\n",
      "32488/32488 [==============================] - 31s 952us/step - loss: 1.1351 - acc: 0.6237 - val_loss: 1.6201 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00873: val_acc did not improve\n",
      "Epoch 874/1000\n",
      "32488/32488 [==============================] - 31s 941us/step - loss: 1.1392 - acc: 0.6177 - val_loss: 1.6191 - val_acc: 0.4702\n",
      "\n",
      "Epoch 00874: val_acc did not improve\n",
      "Epoch 875/1000\n",
      "32488/32488 [==============================] - 31s 941us/step - loss: 1.1392 - acc: 0.6165 - val_loss: 1.6172 - val_acc: 0.4716\n",
      "\n",
      "Epoch 00875: val_acc did not improve\n",
      "Epoch 876/1000\n",
      "32488/32488 [==============================] - 30s 933us/step - loss: 1.1358 - acc: 0.6196 - val_loss: 1.6207 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00876: val_acc did not improve\n",
      "Epoch 877/1000\n",
      "32488/32488 [==============================] - 30s 930us/step - loss: 1.1350 - acc: 0.6197 - val_loss: 1.6189 - val_acc: 0.4714\n",
      "\n",
      "Epoch 00877: val_acc did not improve\n",
      "Epoch 878/1000\n",
      "32488/32488 [==============================] - 31s 948us/step - loss: 1.1324 - acc: 0.6213 - val_loss: 1.6187 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00878: val_acc did not improve\n",
      "Epoch 879/1000\n",
      "32488/32488 [==============================] - 31s 948us/step - loss: 1.1266 - acc: 0.6234 - val_loss: 1.6199 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00879: val_acc did not improve\n",
      "Epoch 880/1000\n",
      "32488/32488 [==============================] - 30s 936us/step - loss: 1.1346 - acc: 0.6198 - val_loss: 1.6195 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00880: val_acc did not improve\n",
      "Epoch 881/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.1238 - acc: 0.6251 - val_loss: 1.6155 - val_acc: 0.4716\n",
      "\n",
      "Epoch 00881: val_acc did not improve\n",
      "Epoch 882/1000\n",
      "32488/32488 [==============================] - 30s 934us/step - loss: 1.1255 - acc: 0.6232 - val_loss: 1.6226 - val_acc: 0.4697\n",
      "\n",
      "Epoch 00882: val_acc did not improve\n",
      "Epoch 883/1000\n",
      "32488/32488 [==============================] - 30s 931us/step - loss: 1.1241 - acc: 0.6244 - val_loss: 1.6167 - val_acc: 0.4721\n",
      "\n",
      "Epoch 00883: val_acc did not improve\n",
      "Epoch 884/1000\n",
      "32488/32488 [==============================] - 31s 943us/step - loss: 1.1242 - acc: 0.6240 - val_loss: 1.6198 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00884: val_acc did not improve\n",
      "Epoch 885/1000\n",
      "32488/32488 [==============================] - 30s 933us/step - loss: 1.1276 - acc: 0.6230 - val_loss: 1.6166 - val_acc: 0.4718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00885: val_acc did not improve\n",
      "Epoch 886/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.1218 - acc: 0.6240 - val_loss: 1.6201 - val_acc: 0.4714\n",
      "\n",
      "Epoch 00886: val_acc did not improve\n",
      "Epoch 887/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.1200 - acc: 0.6265 - val_loss: 1.6176 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00887: val_acc did not improve\n",
      "Epoch 888/1000\n",
      "32488/32488 [==============================] - 31s 944us/step - loss: 1.1202 - acc: 0.6276 - val_loss: 1.6171 - val_acc: 0.4714\n",
      "\n",
      "Epoch 00888: val_acc did not improve\n",
      "Epoch 889/1000\n",
      "32488/32488 [==============================] - 30s 934us/step - loss: 1.1194 - acc: 0.6257 - val_loss: 1.6231 - val_acc: 0.4709\n",
      "\n",
      "Epoch 00889: val_acc did not improve\n",
      "Epoch 890/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.1160 - acc: 0.6255 - val_loss: 1.6195 - val_acc: 0.4704\n",
      "\n",
      "Epoch 00890: val_acc did not improve\n",
      "Epoch 891/1000\n",
      "32488/32488 [==============================] - 30s 936us/step - loss: 1.1187 - acc: 0.6269 - val_loss: 1.6173 - val_acc: 0.4695\n",
      "\n",
      "Epoch 00891: val_acc did not improve\n",
      "Epoch 892/1000\n",
      "32488/32488 [==============================] - 30s 930us/step - loss: 1.1117 - acc: 0.6288 - val_loss: 1.6178 - val_acc: 0.4741\n",
      "\n",
      "Epoch 00892: val_acc improved from 0.47388 to 0.47405, saving model to models/feature_network.h5\n",
      "Epoch 893/1000\n",
      "32488/32488 [==============================] - 31s 951us/step - loss: 1.1188 - acc: 0.6249 - val_loss: 1.6188 - val_acc: 0.4693\n",
      "\n",
      "Epoch 00893: val_acc did not improve\n",
      "Epoch 894/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.1154 - acc: 0.6284 - val_loss: 1.6167 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00894: val_acc did not improve\n",
      "Epoch 895/1000\n",
      "32488/32488 [==============================] - 31s 946us/step - loss: 1.1176 - acc: 0.6261 - val_loss: 1.6173 - val_acc: 0.4702\n",
      "\n",
      "Epoch 00895: val_acc did not improve\n",
      "Epoch 896/1000\n",
      "32488/32488 [==============================] - 31s 948us/step - loss: 1.1108 - acc: 0.6301 - val_loss: 1.6150 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00896: val_acc did not improve\n",
      "Epoch 897/1000\n",
      "32488/32488 [==============================] - 30s 927us/step - loss: 1.1054 - acc: 0.6280 - val_loss: 1.6171 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00897: val_acc did not improve\n",
      "Epoch 898/1000\n",
      "32488/32488 [==============================] - 31s 939us/step - loss: 1.1112 - acc: 0.6300 - val_loss: 1.6183 - val_acc: 0.4725\n",
      "\n",
      "Epoch 00898: val_acc did not improve\n",
      "Epoch 899/1000\n",
      "32488/32488 [==============================] - 30s 928us/step - loss: 1.1072 - acc: 0.6275 - val_loss: 1.6184 - val_acc: 0.4730\n",
      "\n",
      "Epoch 00899: val_acc did not improve\n",
      "Epoch 900/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.1158 - acc: 0.6255 - val_loss: 1.6221 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00900: val_acc did not improve\n",
      "Epoch 901/1000\n",
      "32488/32488 [==============================] - 31s 942us/step - loss: 1.1134 - acc: 0.6267 - val_loss: 1.6179 - val_acc: 0.4749\n",
      "\n",
      "Epoch 00901: val_acc improved from 0.47405 to 0.47493, saving model to models/feature_network.h5\n",
      "Epoch 902/1000\n",
      "32488/32488 [==============================] - 30s 935us/step - loss: 1.1032 - acc: 0.6318 - val_loss: 1.6191 - val_acc: 0.4711\n",
      "\n",
      "Epoch 00902: val_acc did not improve\n",
      "Epoch 903/1000\n",
      "32488/32488 [==============================] - 30s 934us/step - loss: 1.1038 - acc: 0.6324 - val_loss: 1.6168 - val_acc: 0.4704\n",
      "\n",
      "Epoch 00903: val_acc did not improve\n",
      "Epoch 904/1000\n",
      "32488/32488 [==============================] - 31s 941us/step - loss: 1.1026 - acc: 0.6300 - val_loss: 1.6225 - val_acc: 0.4697\n",
      "\n",
      "Epoch 00904: val_acc did not improve\n",
      "Epoch 905/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.1021 - acc: 0.6300 - val_loss: 1.6204 - val_acc: 0.4718\n",
      "\n",
      "Epoch 00905: val_acc did not improve\n",
      "Epoch 906/1000\n",
      "32488/32488 [==============================] - 30s 933us/step - loss: 1.1008 - acc: 0.6318 - val_loss: 1.6270 - val_acc: 0.4697\n",
      "\n",
      "Epoch 00906: val_acc did not improve\n",
      "Epoch 907/1000\n",
      "32488/32488 [==============================] - 30s 934us/step - loss: 1.0956 - acc: 0.6335 - val_loss: 1.6161 - val_acc: 0.4742\n",
      "\n",
      "Epoch 00907: val_acc did not improve\n",
      "Epoch 908/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0981 - acc: 0.6329 - val_loss: 1.6189 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00908: val_acc did not improve\n",
      "Epoch 909/1000\n",
      "32488/32488 [==============================] - 31s 943us/step - loss: 1.0932 - acc: 0.6342 - val_loss: 1.6214 - val_acc: 0.4753\n",
      "\n",
      "Epoch 00909: val_acc improved from 0.47493 to 0.47528, saving model to models/feature_network.h5\n",
      "Epoch 910/1000\n",
      "32488/32488 [==============================] - 31s 945us/step - loss: 1.0950 - acc: 0.6313 - val_loss: 1.6159 - val_acc: 0.4735\n",
      "\n",
      "Epoch 00910: val_acc did not improve\n",
      "Epoch 911/1000\n",
      "32488/32488 [==============================] - 31s 939us/step - loss: 1.0933 - acc: 0.6336 - val_loss: 1.6200 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00911: val_acc did not improve\n",
      "Epoch 912/1000\n",
      "32488/32488 [==============================] - 31s 943us/step - loss: 1.0895 - acc: 0.6379 - val_loss: 1.6178 - val_acc: 0.4748\n",
      "\n",
      "Epoch 00912: val_acc did not improve\n",
      "Epoch 913/1000\n",
      "32488/32488 [==============================] - 31s 940us/step - loss: 1.0925 - acc: 0.6369 - val_loss: 1.6193 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00913: val_acc did not improve\n",
      "Epoch 914/1000\n",
      "32488/32488 [==============================] - 31s 945us/step - loss: 1.0891 - acc: 0.6360 - val_loss: 1.6180 - val_acc: 0.4711\n",
      "\n",
      "Epoch 00914: val_acc did not improve\n",
      "Epoch 915/1000\n",
      "32488/32488 [==============================] - 30s 934us/step - loss: 1.0904 - acc: 0.6355 - val_loss: 1.6162 - val_acc: 0.4716\n",
      "\n",
      "Epoch 00915: val_acc did not improve\n",
      "Epoch 916/1000\n",
      "32488/32488 [==============================] - 30s 935us/step - loss: 1.0924 - acc: 0.6313 - val_loss: 1.6164 - val_acc: 0.4714\n",
      "\n",
      "Epoch 00916: val_acc did not improve\n",
      "Epoch 917/1000\n",
      "32488/32488 [==============================] - 31s 952us/step - loss: 1.0873 - acc: 0.6371 - val_loss: 1.6165 - val_acc: 0.4746\n",
      "\n",
      "Epoch 00917: val_acc did not improve\n",
      "Epoch 918/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0836 - acc: 0.6365 - val_loss: 1.6205 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00918: val_acc did not improve\n",
      "Epoch 919/1000\n",
      "32488/32488 [==============================] - 31s 940us/step - loss: 1.0868 - acc: 0.6371 - val_loss: 1.6190 - val_acc: 0.4730\n",
      "\n",
      "Epoch 00919: val_acc did not improve\n",
      "Epoch 920/1000\n",
      "32488/32488 [==============================] - 31s 943us/step - loss: 1.0876 - acc: 0.6362 - val_loss: 1.6157 - val_acc: 0.4746\n",
      "\n",
      "Epoch 00920: val_acc did not improve\n",
      "Epoch 921/1000\n",
      "32488/32488 [==============================] - 31s 941us/step - loss: 1.0839 - acc: 0.6372 - val_loss: 1.6211 - val_acc: 0.4734\n",
      "\n",
      "Epoch 00921: val_acc did not improve\n",
      "Epoch 922/1000\n",
      "32488/32488 [==============================] - 31s 944us/step - loss: 1.0842 - acc: 0.6400 - val_loss: 1.6193 - val_acc: 0.4730\n",
      "\n",
      "Epoch 00922: val_acc did not improve\n",
      "Epoch 923/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.0812 - acc: 0.6372 - val_loss: 1.6171 - val_acc: 0.4721\n",
      "\n",
      "Epoch 00923: val_acc did not improve\n",
      "Epoch 924/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.0821 - acc: 0.6393 - val_loss: 1.6199 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00924: val_acc did not improve\n",
      "Epoch 925/1000\n",
      "32488/32488 [==============================] - 31s 944us/step - loss: 1.0801 - acc: 0.6379 - val_loss: 1.6192 - val_acc: 0.4721\n",
      "\n",
      "Epoch 00925: val_acc did not improve\n",
      "Epoch 926/1000\n",
      "32488/32488 [==============================] - 30s 923us/step - loss: 1.0809 - acc: 0.6397 - val_loss: 1.6190 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00926: val_acc did not improve\n",
      "Epoch 927/1000\n",
      "32488/32488 [==============================] - 30s 936us/step - loss: 1.0742 - acc: 0.6407 - val_loss: 1.6186 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00927: val_acc did not improve\n",
      "Epoch 928/1000\n",
      "32488/32488 [==============================] - 30s 931us/step - loss: 1.0782 - acc: 0.6399 - val_loss: 1.6257 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00928: val_acc did not improve\n",
      "Epoch 929/1000\n",
      "32488/32488 [==============================] - 31s 945us/step - loss: 1.0763 - acc: 0.6397 - val_loss: 1.6219 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00929: val_acc did not improve\n",
      "Epoch 930/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32488/32488 [==============================] - 30s 930us/step - loss: 1.0799 - acc: 0.6370 - val_loss: 1.6179 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00930: val_acc did not improve\n",
      "Epoch 931/1000\n",
      "32488/32488 [==============================] - 30s 936us/step - loss: 1.0765 - acc: 0.6390 - val_loss: 1.6172 - val_acc: 0.4735\n",
      "\n",
      "Epoch 00931: val_acc did not improve\n",
      "Epoch 932/1000\n",
      "32488/32488 [==============================] - 31s 954us/step - loss: 1.0741 - acc: 0.6405 - val_loss: 1.6202 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00932: val_acc improved from 0.47528 to 0.47667, saving model to models/feature_network.h5\n",
      "Epoch 933/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.0687 - acc: 0.6435 - val_loss: 1.6230 - val_acc: 0.4728\n",
      "\n",
      "Epoch 00933: val_acc did not improve\n",
      "Epoch 934/1000\n",
      "32488/32488 [==============================] - 30s 928us/step - loss: 1.0683 - acc: 0.6421 - val_loss: 1.6183 - val_acc: 0.4756\n",
      "\n",
      "Epoch 00934: val_acc did not improve\n",
      "Epoch 935/1000\n",
      "32488/32488 [==============================] - 30s 934us/step - loss: 1.0669 - acc: 0.6425 - val_loss: 1.6191 - val_acc: 0.4741\n",
      "\n",
      "Epoch 00935: val_acc did not improve\n",
      "Epoch 936/1000\n",
      "32488/32488 [==============================] - 31s 951us/step - loss: 1.0704 - acc: 0.6427 - val_loss: 1.6224 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00936: val_acc did not improve\n",
      "Epoch 937/1000\n",
      "32488/32488 [==============================] - 31s 947us/step - loss: 1.0690 - acc: 0.6425 - val_loss: 1.6186 - val_acc: 0.4728\n",
      "\n",
      "Epoch 00937: val_acc did not improve\n",
      "Epoch 938/1000\n",
      "32488/32488 [==============================] - 30s 927us/step - loss: 1.0679 - acc: 0.6435 - val_loss: 1.6190 - val_acc: 0.4741\n",
      "\n",
      "Epoch 00938: val_acc did not improve\n",
      "Epoch 939/1000\n",
      "32488/32488 [==============================] - 30s 930us/step - loss: 1.0685 - acc: 0.6413 - val_loss: 1.6200 - val_acc: 0.4742\n",
      "\n",
      "Epoch 00939: val_acc did not improve\n",
      "Epoch 940/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0668 - acc: 0.6426 - val_loss: 1.6161 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00940: val_acc did not improve\n",
      "Epoch 941/1000\n",
      "32488/32488 [==============================] - 30s 929us/step - loss: 1.0578 - acc: 0.6485 - val_loss: 1.6179 - val_acc: 0.4735\n",
      "\n",
      "Epoch 00941: val_acc did not improve\n",
      "Epoch 942/1000\n",
      "32488/32488 [==============================] - 31s 952us/step - loss: 1.0643 - acc: 0.6436 - val_loss: 1.6188 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00942: val_acc did not improve\n",
      "Epoch 943/1000\n",
      "32488/32488 [==============================] - 30s 933us/step - loss: 1.0582 - acc: 0.6462 - val_loss: 1.6189 - val_acc: 0.4728\n",
      "\n",
      "Epoch 00943: val_acc did not improve\n",
      "Epoch 944/1000\n",
      "32488/32488 [==============================] - 31s 940us/step - loss: 1.0607 - acc: 0.6455 - val_loss: 1.6206 - val_acc: 0.4699\n",
      "\n",
      "Epoch 00944: val_acc did not improve\n",
      "Epoch 945/1000\n",
      "32488/32488 [==============================] - 30s 932us/step - loss: 1.0584 - acc: 0.6489 - val_loss: 1.6186 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00945: val_acc did not improve\n",
      "Epoch 946/1000\n",
      "32488/32488 [==============================] - 30s 931us/step - loss: 1.0596 - acc: 0.6454 - val_loss: 1.6194 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00946: val_acc did not improve\n",
      "Epoch 947/1000\n",
      "32488/32488 [==============================] - 30s 933us/step - loss: 1.0541 - acc: 0.6452 - val_loss: 1.6186 - val_acc: 0.4742\n",
      "\n",
      "Epoch 00947: val_acc did not improve\n",
      "Epoch 948/1000\n",
      "32488/32488 [==============================] - 31s 947us/step - loss: 1.0560 - acc: 0.6470 - val_loss: 1.6262 - val_acc: 0.4734\n",
      "\n",
      "Epoch 00948: val_acc did not improve\n",
      "Epoch 949/1000\n",
      "32488/32488 [==============================] - 30s 922us/step - loss: 1.0534 - acc: 0.6469 - val_loss: 1.6204 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00949: val_acc did not improve\n",
      "Epoch 950/1000\n",
      "32488/32488 [==============================] - 30s 921us/step - loss: 1.0529 - acc: 0.6485 - val_loss: 1.6180 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00950: val_acc did not improve\n",
      "Epoch 951/1000\n",
      "32488/32488 [==============================] - 30s 932us/step - loss: 1.0549 - acc: 0.6510 - val_loss: 1.6206 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00951: val_acc did not improve\n",
      "Epoch 952/1000\n",
      "32488/32488 [==============================] - 30s 936us/step - loss: 1.0561 - acc: 0.6473 - val_loss: 1.6216 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00952: val_acc did not improve\n",
      "Epoch 953/1000\n",
      "32488/32488 [==============================] - 30s 935us/step - loss: 1.0523 - acc: 0.6472 - val_loss: 1.6201 - val_acc: 0.4786\n",
      "\n",
      "Epoch 00953: val_acc improved from 0.47667 to 0.47860, saving model to models/feature_network.h5\n",
      "Epoch 954/1000\n",
      "32488/32488 [==============================] - 31s 940us/step - loss: 1.0511 - acc: 0.6466 - val_loss: 1.6175 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00954: val_acc did not improve\n",
      "Epoch 955/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0445 - acc: 0.6505 - val_loss: 1.6176 - val_acc: 0.4788\n",
      "\n",
      "Epoch 00955: val_acc improved from 0.47860 to 0.47877, saving model to models/feature_network.h5\n",
      "Epoch 956/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0466 - acc: 0.6515 - val_loss: 1.6210 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00956: val_acc did not improve\n",
      "Epoch 957/1000\n",
      "32488/32488 [==============================] - 31s 951us/step - loss: 1.0441 - acc: 0.6520 - val_loss: 1.6209 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00957: val_acc did not improve\n",
      "Epoch 958/1000\n",
      "32488/32488 [==============================] - 31s 958us/step - loss: 1.0456 - acc: 0.6518 - val_loss: 1.6182 - val_acc: 0.4770\n",
      "\n",
      "Epoch 00958: val_acc did not improve\n",
      "Epoch 959/1000\n",
      "32488/32488 [==============================] - 31s 947us/step - loss: 1.0427 - acc: 0.6491 - val_loss: 1.6173 - val_acc: 0.4732\n",
      "\n",
      "Epoch 00959: val_acc did not improve\n",
      "Epoch 960/1000\n",
      "32488/32488 [==============================] - 31s 947us/step - loss: 1.0428 - acc: 0.6527 - val_loss: 1.6178 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00960: val_acc did not improve\n",
      "Epoch 961/1000\n",
      "32488/32488 [==============================] - 31s 955us/step - loss: 1.0420 - acc: 0.6511 - val_loss: 1.6223 - val_acc: 0.4763\n",
      "\n",
      "Epoch 00961: val_acc did not improve\n",
      "Epoch 962/1000\n",
      "32488/32488 [==============================] - 31s 950us/step - loss: 1.0423 - acc: 0.6519 - val_loss: 1.6158 - val_acc: 0.4761\n",
      "\n",
      "Epoch 00962: val_acc did not improve\n",
      "Epoch 963/1000\n",
      "32488/32488 [==============================] - 30s 931us/step - loss: 1.0382 - acc: 0.6539 - val_loss: 1.6169 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00963: val_acc did not improve\n",
      "Epoch 964/1000\n",
      "32488/32488 [==============================] - 31s 955us/step - loss: 1.0362 - acc: 0.6553 - val_loss: 1.6184 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00964: val_acc did not improve\n",
      "Epoch 965/1000\n",
      "32488/32488 [==============================] - 31s 943us/step - loss: 1.0353 - acc: 0.6548 - val_loss: 1.6206 - val_acc: 0.4737\n",
      "\n",
      "Epoch 00965: val_acc did not improve\n",
      "Epoch 966/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.0357 - acc: 0.6539 - val_loss: 1.6199 - val_acc: 0.4758\n",
      "\n",
      "Epoch 00966: val_acc did not improve\n",
      "Epoch 967/1000\n",
      "32488/32488 [==============================] - 31s 948us/step - loss: 1.0357 - acc: 0.6543 - val_loss: 1.6190 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00967: val_acc did not improve\n",
      "Epoch 968/1000\n",
      "32488/32488 [==============================] - 31s 947us/step - loss: 1.0329 - acc: 0.6536 - val_loss: 1.6195 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00968: val_acc did not improve\n",
      "Epoch 969/1000\n",
      "32488/32488 [==============================] - 31s 953us/step - loss: 1.0321 - acc: 0.6540 - val_loss: 1.6225 - val_acc: 0.4758\n",
      "\n",
      "Epoch 00969: val_acc did not improve\n",
      "Epoch 970/1000\n",
      "32488/32488 [==============================] - 31s 954us/step - loss: 1.0321 - acc: 0.6571 - val_loss: 1.6179 - val_acc: 0.4732\n",
      "\n",
      "Epoch 00970: val_acc did not improve\n",
      "Epoch 971/1000\n",
      "32488/32488 [==============================] - 31s 941us/step - loss: 1.0316 - acc: 0.6566 - val_loss: 1.6210 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00971: val_acc did not improve\n",
      "Epoch 972/1000\n",
      "32488/32488 [==============================] - 31s 945us/step - loss: 1.0295 - acc: 0.6553 - val_loss: 1.6206 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00972: val_acc did not improve\n",
      "Epoch 973/1000\n",
      "32488/32488 [==============================] - 31s 952us/step - loss: 1.0302 - acc: 0.6565 - val_loss: 1.6325 - val_acc: 0.4704\n",
      "\n",
      "Epoch 00973: val_acc did not improve\n",
      "Epoch 974/1000\n",
      "32488/32488 [==============================] - 31s 965us/step - loss: 1.0255 - acc: 0.6580 - val_loss: 1.6216 - val_acc: 0.4711\n",
      "\n",
      "Epoch 00974: val_acc did not improve\n",
      "Epoch 975/1000\n",
      "32488/32488 [==============================] - 31s 949us/step - loss: 1.0173 - acc: 0.6590 - val_loss: 1.6198 - val_acc: 0.4763\n",
      "\n",
      "Epoch 00975: val_acc did not improve\n",
      "Epoch 976/1000\n",
      "32488/32488 [==============================] - 31s 947us/step - loss: 1.0259 - acc: 0.6567 - val_loss: 1.6198 - val_acc: 0.4741\n",
      "\n",
      "Epoch 00976: val_acc did not improve\n",
      "Epoch 977/1000\n",
      "32488/32488 [==============================] - 31s 960us/step - loss: 1.0223 - acc: 0.6578 - val_loss: 1.6207 - val_acc: 0.4742\n",
      "\n",
      "Epoch 00977: val_acc did not improve\n",
      "Epoch 978/1000\n",
      "32488/32488 [==============================] - 30s 934us/step - loss: 1.0151 - acc: 0.6639 - val_loss: 1.6236 - val_acc: 0.4748\n",
      "\n",
      "Epoch 00978: val_acc did not improve\n",
      "Epoch 979/1000\n",
      "32488/32488 [==============================] - 30s 935us/step - loss: 1.0193 - acc: 0.6601 - val_loss: 1.6205 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00979: val_acc did not improve\n",
      "Epoch 980/1000\n",
      "32488/32488 [==============================] - 31s 942us/step - loss: 1.0145 - acc: 0.6636 - val_loss: 1.6177 - val_acc: 0.4741\n",
      "\n",
      "Epoch 00980: val_acc did not improve\n",
      "Epoch 981/1000\n",
      "32488/32488 [==============================] - 30s 935us/step - loss: 1.0209 - acc: 0.6570 - val_loss: 1.6224 - val_acc: 0.4716\n",
      "\n",
      "Epoch 00981: val_acc did not improve\n",
      "Epoch 982/1000\n",
      "32488/32488 [==============================] - 30s 929us/step - loss: 1.0210 - acc: 0.6575 - val_loss: 1.6181 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00982: val_acc did not improve\n",
      "Epoch 983/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0188 - acc: 0.6575 - val_loss: 1.6185 - val_acc: 0.4735\n",
      "\n",
      "Epoch 00983: val_acc did not improve\n",
      "Epoch 984/1000\n",
      "32488/32488 [==============================] - 31s 949us/step - loss: 1.0155 - acc: 0.6562 - val_loss: 1.6221 - val_acc: 0.4734\n",
      "\n",
      "Epoch 00984: val_acc did not improve\n",
      "Epoch 985/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0206 - acc: 0.6584 - val_loss: 1.6180 - val_acc: 0.4742\n",
      "\n",
      "Epoch 00985: val_acc did not improve\n",
      "Epoch 986/1000\n",
      "32488/32488 [==============================] - 30s 925us/step - loss: 1.0174 - acc: 0.6603 - val_loss: 1.6193 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00986: val_acc did not improve\n",
      "Epoch 987/1000\n",
      "32488/32488 [==============================] - 30s 937us/step - loss: 1.0143 - acc: 0.6588 - val_loss: 1.6196 - val_acc: 0.4742\n",
      "\n",
      "Epoch 00987: val_acc did not improve\n",
      "Epoch 988/1000\n",
      "32488/32488 [==============================] - 31s 940us/step - loss: 1.0144 - acc: 0.6604 - val_loss: 1.6168 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00988: val_acc did not improve\n",
      "Epoch 989/1000\n",
      "32488/32488 [==============================] - 31s 945us/step - loss: 1.0124 - acc: 0.6623 - val_loss: 1.6190 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00989: val_acc did not improve\n",
      "Epoch 990/1000\n",
      "32488/32488 [==============================] - 30s 933us/step - loss: 1.0105 - acc: 0.6608 - val_loss: 1.6193 - val_acc: 0.4756\n",
      "\n",
      "Epoch 00990: val_acc did not improve\n",
      "Epoch 991/1000\n",
      "32488/32488 [==============================] - 31s 941us/step - loss: 1.0096 - acc: 0.6630 - val_loss: 1.6201 - val_acc: 0.4758\n",
      "\n",
      "Epoch 00991: val_acc did not improve\n",
      "Epoch 992/1000\n",
      "32488/32488 [==============================] - 30s 938us/step - loss: 1.0068 - acc: 0.6640 - val_loss: 1.6236 - val_acc: 0.4728\n",
      "\n",
      "Epoch 00992: val_acc did not improve\n",
      "Epoch 993/1000\n",
      "32488/32488 [==============================] - 31s 945us/step - loss: 1.0088 - acc: 0.6639 - val_loss: 1.6206 - val_acc: 0.4774\n",
      "\n",
      "Epoch 00993: val_acc did not improve\n",
      "Epoch 994/1000\n",
      "32488/32488 [==============================] - 31s 944us/step - loss: 1.0092 - acc: 0.6627 - val_loss: 1.6217 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00994: val_acc did not improve\n",
      "Epoch 995/1000\n",
      "32488/32488 [==============================] - 30s 927us/step - loss: 1.0062 - acc: 0.6647 - val_loss: 1.6239 - val_acc: 0.4758\n",
      "\n",
      "Epoch 00995: val_acc did not improve\n",
      "Epoch 996/1000\n",
      "32488/32488 [==============================] - 30s 936us/step - loss: 1.0066 - acc: 0.6634 - val_loss: 1.6161 - val_acc: 0.4763\n",
      "\n",
      "Epoch 00996: val_acc did not improve\n",
      "Epoch 997/1000\n",
      "32488/32488 [==============================] - 31s 943us/step - loss: 1.0078 - acc: 0.6652 - val_loss: 1.6176 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00997: val_acc did not improve\n",
      "Epoch 998/1000\n",
      "32488/32488 [==============================] - 30s 932us/step - loss: 1.0015 - acc: 0.6666 - val_loss: 1.6200 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00998: val_acc did not improve\n",
      "Epoch 999/1000\n",
      "32488/32488 [==============================] - 26s 795us/step - loss: 1.0001 - acc: 0.6650 - val_loss: 1.6236 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00999: val_acc did not improve\n",
      "Epoch 1000/1000\n",
      "32488/32488 [==============================] - 20s 630us/step - loss: 0.9990 - acc: 0.6672 - val_loss: 1.6210 - val_acc: 0.4756\n",
      "\n",
      "Epoch 01000: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, Y_train, \n",
    "          epochs=epochs, batch_size=batch_size, \n",
    "          callbacks = [checkpoint],\n",
    "          initial_epoch = 365,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = 635\n",
    "plt.plot(np.arange(365, N+365), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(365, N+365), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('feature_network_con.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
